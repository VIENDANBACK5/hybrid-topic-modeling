#!/usr/bin/env python3
"""
Test script ƒë·ªÉ demo vi·ªác l∆∞u BERTopic discovered topics v√†o database
"""

import sys
import time
from datetime import datetime
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# Mock BERTopic result for demonstration
MOCK_BERTOPIC_RESULT = {
    'topics': [
        {
            'topic_id': 0,
            'natural_label': 'Ch√≠nh tr·ªã & Ch√≠nh ph·ªß',
            'description': 'C√°c ch·ªß ƒë·ªÅ v·ªÅ ch√≠nh tr·ªã, qu·ªëc h·ªôi, ch√≠nh ph·ªß',
            'count': 45,
            'words': [
                {'word': 'ch√≠nh ph·ªß', 'score': 0.85},
                {'word': 'qu·ªëc h·ªôi', 'score': 0.78},
                {'word': 'ngh·ªã quy·∫øt', 'score': 0.72},
                {'word': 'b·ªô tr∆∞·ªüng', 'score': 0.68},
                {'word': 'ch√≠nh s√°ch', 'score': 0.65},
            ],
            'representative_docs': [
                'Qu·ªëc h·ªôi th√¥ng qua ngh·ªã quy·∫øt v·ªÅ ch√≠nh s√°ch t√†i ch√≠nh',
                'Ch√≠nh ph·ªß ban h√†nh quy ƒë·ªãnh m·ªõi v·ªÅ ƒë·∫ßu t∆∞',
                'B·ªô tr∆∞·ªüng tr√¨nh b√†y b√°o c√°o t·∫°i phi√™n h·ªçp'
            ]
        },
        {
            'topic_id': 1,
            'natural_label': 'Kinh t·∫ø & ƒê·∫ßu t∆∞',
            'description': 'C√°c tin v·ªÅ kinh t·∫ø, ƒë·∫ßu t∆∞, t√†i ch√≠nh',
            'count': 38,
            'words': [
                {'word': 'ƒë·∫ßu t∆∞', 'score': 0.88},
                {'word': 'kinh t·∫ø', 'score': 0.82},
                {'word': 'doanh nghi·ªáp', 'score': 0.75},
                {'word': 'tƒÉng tr∆∞·ªüng', 'score': 0.70},
                {'word': 'th·ªã tr∆∞·ªùng', 'score': 0.67},
            ],
            'representative_docs': [
                'TƒÉng tr∆∞·ªüng kinh t·∫ø ƒë·∫°t 6.5% trong qu√Ω III',
                'Doanh nghi·ªáp FDI ƒë·∫ßu t∆∞ 2 t·ª∑ USD v√†o Vi·ªát Nam',
                'Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n ph·ª•c h·ªìi m·∫°nh m·∫Ω'
            ]
        },
        {
            'topic_id': 2,
            'natural_label': 'Du l·ªãch & VƒÉn h√≥a',
            'description': 'C√°c b√†i v·ªÅ du l·ªãch, di s·∫£n vƒÉn h√≥a',
            'count': 32,
            'words': [
                {'word': 'du l·ªãch', 'score': 0.90},
                {'word': 'di s·∫£n', 'score': 0.80},
                {'word': 'l·ªÖ h·ªôi', 'score': 0.75},
                {'word': 'vƒÉn h√≥a', 'score': 0.72},
                {'word': 'du kh√°ch', 'score': 0.68},
            ],
            'representative_docs': [
                'H∆∞ng Y√™n ph√°t tri·ªÉn du l·ªãch di s·∫£n vƒÉn h√≥a Ph·ªë Hi·∫øn',
                'L·ªÖ h·ªôi truy·ªÅn th·ªëng thu h√∫t h√†ng ngh√¨n du kh√°ch',
                'Di s·∫£n vƒÉn h√≥a phi v·∫≠t th·ªÉ ƒë∆∞·ª£c b·∫£o t·ªìn'
            ]
        },
        {
            'topic_id': 3,
            'natural_label': 'Gi√°o d·ª•c & ƒê√†o t·∫°o',
            'description': 'Tin t·ª©c v·ªÅ gi√°o d·ª•c, tr∆∞·ªùng h·ªçc, thi c·ª≠',
            'count': 28,
            'words': [
                {'word': 'gi√°o d·ª•c', 'score': 0.87},
                {'word': 'tr∆∞·ªùng h·ªçc', 'score': 0.79},
                {'word': 'h·ªçc sinh', 'score': 0.76},
                {'word': 'thi c·ª≠', 'score': 0.71},
                {'word': 'ƒë√†o t·∫°o', 'score': 0.68},
            ],
            'representative_docs': [
                'Tr∆∞·ªùng h·ªçc ƒë·∫ßu t∆∞ c∆° s·ªü v·∫≠t ch·∫•t hi·ªán ƒë·∫°i',
                'H·ªçc sinh ƒë·∫°t gi·∫£i qu·ªëc gia m√¥n to√°n',
                'K·ª≥ thi t·ªët nghi·ªáp THPT di·ªÖn ra thu·∫≠n l·ª£i'
            ]
        },
        {
            'topic_id': 4,
            'natural_label': 'Y t·∫ø & S·ª©c kh·ªèe',
            'description': 'C√°c tin v·ªÅ y t·∫ø, b·ªánh vi·ªán, chƒÉm s√≥c s·ª©c kh·ªèe',
            'count': 25,
            'words': [
                {'word': 'y t·∫ø', 'score': 0.89},
                {'word': 'b·ªánh vi·ªán', 'score': 0.83},
                {'word': 'b·ªánh nh√¢n', 'score': 0.77},
                {'word': 's·ª©c kh·ªèe', 'score': 0.74},
                {'word': 'vaccine', 'score': 0.69},
            ],
            'representative_docs': [
                'B·ªánh vi·ªán ƒëa khoa t·ªânh n√¢ng c·∫•p trang thi·∫øt b·ªã',
                'Ch∆∞∆°ng tr√¨nh ti√™m ch·ªßng mi·ªÖn ph√≠ cho tr·∫ª em',
                'B·ªánh nh√¢n COVID-19 ƒë∆∞·ª£c ƒëi·ªÅu tr·ªã th√†nh c√¥ng'
            ]
        },
        {
            'topic_id': -1,
            'natural_label': 'Outliers',
            'description': 'C√°c b√†i kh√¥ng thu·ªôc topic n√†o r√µ r√†ng',
            'count': 12,
            'words': [],
            'representative_docs': []
        }
    ]
}

MOCK_DOCUMENT_TOPICS = [
    {'doc_id': 324, 'topic_id': 0, 'probability': 0.85},
    {'doc_id': 325, 'topic_id': 0, 'probability': 0.78},
    {'doc_id': 326, 'topic_id': 1, 'probability': 0.92},
    {'doc_id': 327, 'topic_id': 1, 'probability': 0.76},
    {'doc_id': 328, 'topic_id': 2, 'probability': 0.88},
    {'doc_id': 329, 'topic_id': 2, 'probability': 0.81},
    {'doc_id': 330, 'topic_id': 3, 'probability': 0.79},
    {'doc_id': 331, 'topic_id': 3, 'probability': 0.85},
    {'doc_id': 332, 'topic_id': 4, 'probability': 0.90},
    {'doc_id': 333, 'topic_id': 4, 'probability': 0.77},
    {'doc_id': 334, 'topic_id': -1, 'probability': 0.30},
    {'doc_id': 335, 'topic_id': -1, 'probability': 0.25},
]

def main():
    print("\n" + "="*80)
    print("DEMO: L∆∞u BERTopic Discovered Topics v√†o Database")
    print("="*80 + "\n")
    
    # Import saver
    sys.path.insert(0, '/app')
    from app.services.topic.bertopic_saver import BertopicTopicSaver
    
    # Connect to database
    DATABASE_URL = "postgresql://postgres:postgres@db:5432/DBHuYe"
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(bind=engine)
    db = SessionLocal()
    
    try:
        saver = BertopicTopicSaver()
        
        # Mock training parameters
        training_params = {
            'model_type': 'bertopic',
            'model_version': 'v1.0.0',
            'min_topic_size': 10,
            'embedding_model': 'paraphrase-multilingual-MiniLM-L12-v2',
            'use_vietnamese_tokenizer': True,
            'use_topicgpt': False,
            'num_documents': 200,
            'training_duration_seconds': 45.5
        }
        
        print("üöÄ B∆∞·ªõc 1: L∆∞u th√¥ng tin training session...")
        start_time = time.time()
        
        session_id = saver.save_full_training_result(
            db=db,
            topic_model_result=MOCK_BERTOPIC_RESULT,
            training_params=training_params,
            document_topics=MOCK_DOCUMENT_TOPICS,
            model_saved_path='/app/data/models/bertopic_model_20240115.pkl',
            notes='Demo training session - Mock data'
        )
        
        elapsed = time.time() - start_time
        
        print(f"‚úÖ Ho√†n th√†nh trong {elapsed:.2f}s")
        print(f"\nüìã Training Session ID: {session_id}")
        
        # Query results
        print("\n" + "-"*80)
        print("üìä K·∫æT QU·∫¢ ƒê√É L∆ØU:")
        print("-"*80 + "\n")
        
        # Training session
        from app.models.model_bertopic_discovered import TopicTrainingSession
        session = db.query(TopicTrainingSession).filter(
            TopicTrainingSession.session_id == session_id
        ).first()
        
        print(f"‚úÖ Training Session:")
        print(f"   - Session ID: {session.session_id}")
        print(f"   - Model: {session.model_type}")
        print(f"   - Documents: {session.num_documents}")
        print(f"   - Topics found: {session.num_topics_found}")
        print(f"   - Outliers: {session.num_outliers}")
        print(f"   - Duration: {session.training_duration_seconds}s")
        print(f"   - Status: {session.status}")
        print(f"   - Model path: {session.model_saved_path}")
        
        # Discovered topics
        from app.models.model_bertopic_discovered import BertopicDiscoveredTopic
        topics = db.query(BertopicDiscoveredTopic).filter(
            BertopicDiscoveredTopic.training_session_id == session_id
        ).order_by(BertopicDiscoveredTopic.topic_id).all()
        
        print(f"\n‚úÖ Discovered Topics: {len(topics)} topics")
        for topic in topics:
            if topic.is_outlier:
                print(f"   {topic.topic_id}. {topic.topic_label} (outlier)")
                print(f"      - Documents: {topic.document_count}")
            else:
                keywords = [f"{kw['word']} ({kw['score']:.2f})" for kw in topic.keywords[:3]]
                print(f"   {topic.topic_id}. {topic.topic_label}")
                print(f"      - Documents: {topic.document_count}")
                print(f"      - Keywords: {', '.join(keywords)}")
        
        # Article mappings
        from app.models.model_bertopic_discovered import ArticleBertopicTopic
        mappings_count = db.query(ArticleBertopicTopic).filter(
            ArticleBertopicTopic.training_session_id == session_id
        ).count()
        
        print(f"\n‚úÖ Article-Topic Mappings: {mappings_count} mappings")
        
        # Sample mappings
        from sqlalchemy import func
        sample_mappings = db.query(
            ArticleBertopicTopic.article_id,
            BertopicDiscoveredTopic.topic_label,
            ArticleBertopicTopic.probability
        ).join(
            BertopicDiscoveredTopic,
            ArticleBertopicTopic.bertopic_topic_id == BertopicDiscoveredTopic.id
        ).filter(
            ArticleBertopicTopic.training_session_id == session_id,
            BertopicDiscoveredTopic.topic_id != -1
        ).order_by(
            ArticleBertopicTopic.probability.desc()
        ).limit(5).all()
        
        print("\n   Top 5 mappings by confidence:")
        for article_id, topic_label, prob in sample_mappings:
            print(f"   - Article {article_id} ‚Üí {topic_label} ({prob:.2f})")
        
        # Topic distribution
        topic_dist = db.query(
            BertopicDiscoveredTopic.topic_label,
            func.count(ArticleBertopicTopic.id).label('count')
        ).join(
            ArticleBertopicTopic,
            BertopicDiscoveredTopic.id == ArticleBertopicTopic.bertopic_topic_id
        ).filter(
            BertopicDiscoveredTopic.training_session_id == session_id,
            BertopicDiscoveredTopic.topic_id != -1
        ).group_by(
            BertopicDiscoveredTopic.topic_label
        ).order_by(
            func.count(ArticleBertopicTopic.id).desc()
        ).all()
        
        print("\nüìà Ph√¢n b·ªë articles theo topic:")
        for topic_label, count in topic_dist:
            print(f"   - {topic_label}: {count} articles")
        
        print("\n" + "="*80)
        print("‚úÖ DEMO HO√ÄN TH√ÄNH!")
        print("="*80)
        print("\nüí° Khi train BERTopic th·ª±c t·∫ø, ch·ªâ c·∫ßn g·ªçi:")
        print("   saver.save_full_training_result(db, topic_model_result, params, doc_topics)")
        print("\nüìù D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o 3 b·∫£ng:")
        print("   1. topic_training_sessions - Th√¥ng tin session")
        print("   2. bertopic_discovered_topics - C√°c topics ph√°t hi·ªán ƒë∆∞·ª£c")
        print("   3. article_bertopic_topics - Mapping articles ‚Üî topics")
        print("\nüîÑ C√≥ th·ªÉ:")
        print("   - Review c√°c topics ph√°t hi·ªán ƒë∆∞·ª£c")
        print("   - Convert sang custom topics")
        print("   - Theo d√µi evolution c·ªßa topics qua c√°c l·∫ßn training")
        print("   - So s√°nh custom vs discovered topics\n")
        
    except Exception as e:
        print(f"\n‚ùå L·ªói: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        db.close()
    
    return 0

if __name__ == '__main__':
    sys.exit(main())
