# Hybrid Topic Training - Implementation Summary

## ğŸ“‹ **Overview**

Implemented **Option 3: Hybrid Approach** combining full training and incremental updates for optimal performance.

## ğŸ—ï¸ **Architecture**

### Components Created:

1. **`hybrid_trainer.py`** - Core hybrid training logic
2. **API Endpoints** in `topic_service.py`:
   - `POST /topic-service/hybrid-train` - Smart training
   - `GET /topic-service/training-recommendation` - Analysis

## ğŸ¯ **Strategy**

### **Full Training** (triggered when):
- âœ… No previous training found
- âœ… 30+ days since last training
- âœ… Concept drift > 30% threshold
- âœ… 20%+ new data ratio
- âœ… Force flag = true

### **Transform Only** (when):
- âŒ Recent training (<30 days)
- âŒ Low concept drift (<30%)
- âŒ Small amount of new data (<20%)

## ğŸ“Š **Concept Drift Detection**

Compares topic distribution:
- **Recent**: Last 7 days
- **Historical**: 30-7 days ago
- **Method**: Jensen-Shannon divergence
- **Threshold**: 0.3 (30% distribution change)

## ğŸš€ **Usage**

### 1. Check Recommendation:
```bash
curl -X GET http://localhost:7777/topic-service/training-recommendation
```

**Response:**
```json
{
  "recommendation": "full_train",
  "reason": "No previous training found",
  "analysis": {
    "last_training": null,
    "days_since_training": null,
    "new_articles": 0,
    "total_articles": 8320,
    "new_ratio": 0,
    "concept_drift_score": 0.0,
    "drift_threshold": 0.3
  }
}
```

### 2. Execute Hybrid Training:
```bash
# Auto decision (recommended)
curl -X POST http://localhost:7777/topic-service/hybrid-train \
  -H "Content-Type: application/json" \
  -d '{
    "min_topic_size": 10,
    "use_vietnamese_tokenizer": true
  }'

# Force full training
curl -X POST "http://localhost:7777/topic-service/hybrid-train?force_full=true" \
  -H "Content-Type: application/json" \
  -d '{
    "min_topic_size": 10,
    "use_vietnamese_tokenizer": true
  }'
```

## ğŸ“ˆ **Workflow**

### **Daily Schedule:**
```bash
# 1. Fetch new data
curl -X POST http://localhost:7777/api/fetch/all

# 2. Process all types
curl -X POST http://localhost:7777/api/process/all

# 3. Load to DB (auto skip duplicates)
for type in facebook tiktok threads newspaper; do
  curl -X POST http://localhost:7777/api/process/load-to-db \
    -H "Content-Type: application/json" \
    -d "{\"processed_file\": \"${type}_processed_latest.json\"}"
done

# 4. Smart training
curl -X POST http://localhost:7777/topic-service/hybrid-train
```

### **Monthly Schedule:**
```bash
# Force full retrain for topics over time accuracy
curl -X POST "http://localhost:7777/topic-service/hybrid-train?force_full=true"
```

## ğŸ”§ **Configuration**

Edit `/app/services/topic/hybrid_trainer.py`:

```python
class HybridTopicTrainer:
    def __init__(self, db: Session):
        self.drift_threshold = 0.3  # 30% drift triggers retrain
```

**Tunable parameters:**
- `drift_threshold`: 0.1-0.5 (lower = more sensitive)
- Days threshold: 30 days (line 45)
- New data ratio: 0.2 = 20% (line 60)

## ğŸ“Š **Performance**

| Scenario | Method | Time | Data Used |
|----------|--------|------|-----------|
| First run | Full train | ~5 min | All 8,320 |
| Daily (+100 new) | Transform | ~10 sec | 100 new |
| Weekly (+1000 new) | Full train | ~5 min | All 9,320 |
| Drift detected | Full train | ~5 min | All data |

## âœ… **Benefits**

1. **Speed**: 30x faster for daily updates (10s vs 5min)
2. **Accuracy**: Full retrain when needed
3. **Consistency**: Topics stay comparable over time
4. **Automation**: Smart decision making

## ğŸ¯ **Topics Over Time**

For accurate `topics_over_time` analysis:
- Full retrain: Monthly
- Transform: Daily for new data
- Model stays consistent for trend comparison

## ğŸ” **Monitoring**

Check training status:
```bash
curl -X GET http://localhost:7777/topic-service/status
```

View training history:
```sql
SELECT * FROM bertopic_training_sessions 
ORDER BY started_at DESC LIMIT 10;
```

## ğŸ“ **Notes**

- First training must be full (no model exists)
- Transform requires existing model
- Drift detection needs 30+ days of data
- All counts are cached in analysis endpoint
