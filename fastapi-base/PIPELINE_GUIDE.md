# Pipeline Automation Guide

## üéØ T·ªïng quan

H·ªá th·ªëng c√≥ **Orchestrator t·ª± ƒë·ªông** ƒëi·ªÅu ph·ªëi to√†n b·ªô lu·ªìng x·ª≠ l√Ω data.

## üöÄ 3 C√°ch ch·∫°y Pipeline

### 1Ô∏è‚É£ API Endpoint (Recommended)

```bash
# Full pipeline (foreground - ƒë·ª£i k·∫øt qu·∫£)
curl -X POST http://localhost:7777/api/orchestrator/run-full-pipeline

# Background (kh√¥ng block)
curl -X POST "http://localhost:7777/api/orchestrator/run-full-pipeline?background=true"

# Quick update (ch·ªâ classify + sentiment + keywords)
curl -X POST "http://localhost:7777/api/orchestrator/quick-update?limit=200"

# Check status
curl http://localhost:7777/api/orchestrator/status
```

### 2Ô∏è‚É£ Shell Script

```bash
# Ch·∫°y full pipeline
./scripts/run_full_pipeline.sh

# Custom limit
LIMIT=1000 ./scripts/run_full_pipeline.sh

# Background mode
BACKGROUND=true ./scripts/run_full_pipeline.sh
```

### 3Ô∏è‚É£ Python Code

```python
from app.services.orchestrator import PipelineOrchestrator
from app.core.database import SessionLocal

db = SessionLocal()
orchestrator = PipelineOrchestrator(db)

result = orchestrator.run_full_pipeline(
    sync_data=False,           # Skip external API sync
    classify_topics=True,      # Classify unclassified articles
    analyze_sentiment=True,    # Analyze sentiment + link topics
    calculate_statistics=True, # Update stats tables
    regenerate_keywords=True,  # Regenerate keywords with GPT
    train_bertopic=False,      # Skip BERTopic training (expensive)
    limit=500                  # Process max 500 articles
)

print(f"Success: {result['steps']}")
db.close()
```

## üìã Pipeline Workflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   PIPELINE WORKFLOW                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

1. üì• Sync Data (optional)
   ‚îî‚îÄ> Call external API ‚Üí Load articles into DB

2. üè∑Ô∏è  Classify Topics
   ‚îî‚îÄ> Find unclassified articles
   ‚îî‚îÄ> Run CustomTopicClassifier
   ‚îî‚îÄ> Save to article_custom_topics

3. üòä Analyze Sentiment
   ‚îî‚îÄ> Get articles with topics but no sentiment
   ‚îî‚îÄ> Run sentiment analysis
   ‚îî‚îÄ> Link sentiment to topics
   ‚îî‚îÄ> Update topic_mention_stats

4. üìä Calculate Statistics
   ‚îî‚îÄ> Update trend_reports (weekly)
   ‚îî‚îÄ> Calculate hot_topics (top 10)
   ‚îî‚îÄ> Create daily_snapshot

5. üîë Regenerate Keywords
   ‚îî‚îÄ> Extract n-grams from articles
   ‚îî‚îÄ> GPT-4 cleaning (entity preservation)
   ‚îî‚îÄ> Save to keyword_stats

6. ü§ñ Train BERTopic (optional, expensive)
   ‚îî‚îÄ> Train BERTopic model on all articles
   ‚îî‚îÄ> Save discovered topics
```

## ‚öôÔ∏è Configuration Options

| Parameter | Default | Description |
|-----------|---------|-------------|
| `sync_data` | `true` | Sync t·ª´ external API |
| `classify_topics` | `true` | Classify topics |
| `analyze_sentiment` | `true` | Ph√¢n t√≠ch sentiment |
| `calculate_statistics` | `true` | T√≠nh statistics |
| `regenerate_keywords` | `true` | T·∫°o keywords m·ªõi |
| `train_bertopic` | `true` | Train BERTopic discover topics |
| `limit` | `None` | Gi·ªõi h·∫°n articles x·ª≠ l√Ω |

## üîÑ Khi n√†o ch·∫°y?

### H√†ng ng√†y (Quick Update)
```bash
curl -X POST "http://localhost:7777/api/orchestrator/quick-update?limit=200"
```
- Ch·ªâ x·ª≠ l√Ω data m·ªõi (classify + sentiment + keywords)
- Nhanh (< 1 ph√∫t)
- Kh√¥ng sync, kh√¥ng train

### H√†ng tu·∫ßn (Full Pipeline)
```bash
curl -X POST http://localhost:7777/api/orchestrator/run-full-pipeline
```
- Full workflow bao g·ªìm statistics + BERTopic training
- Discover topics m·ªõi t·ª´ data
- Trung b√¨nh (10-30 ph√∫t t√πy data size)

### Train Topics ri√™ng (Khi c·∫ßn discover topics m·ªõi)
```bash
curl -X POST http://localhost:7777/api/topics/train \
  -H "Content-Type: application/json" \
  -d '{"limit": 500, "min_topic_size": 10}'
```
- Ch·ªâ train BERTopic
- Discover topics t·ª´ articles
- Save v√†o `bertopic_discovered_topics`
- 5-15 ph√∫t

### Khi c√≥ data l·ªõn m·ªõi
```bash
# 1. Sync data tr∆∞·ªõc
curl -X POST http://localhost:7777/api/v1/sync/all

# 2. Ch·∫°y full pipeline
LIMIT=5000 ./scripts/run_full_pipeline.sh
```

## üìä Monitoring

### Check Status
```bash
curl http://localhost:7777/api/orchestrator/status
```

Response:
```json
{
  "status": "ok",
  "totals": {
    "articles": 200,
    "topics": 12,
    "classifications": 47,
    "sentiments": 45,
    "keywords": 27
  },
  "pending": {
    "unclassified_articles": 0,
    "articles_no_sentiment": 2
  },
  "needs_action": true
}
```

### Check Logs
```bash
tail -f logs/app.log | grep -E "PIPELINE|Step"
```

## üéõÔ∏è API Docs

Swagger UI: http://localhost:7777/docs
- T√¨m section "üéØ Orchestrator"
- Test endpoints tr·ª±c ti·∫øp

## üîß Troubleshooting

### Pipeline fails v·ªõi DB error
```bash
# Check DB connection
export POSTGRES_PORT=5555
psql postgresql://postgres:postgres@localhost:5555/DBHuYe -c "SELECT COUNT(*) FROM articles"
```

### Kh√¥ng c√≥ OpenAI API key
```bash
# Set key tr∆∞·ªõc khi ch·∫°y
export OPENAI_API_KEY='sk-...'
```

### Pipeline ch·∫°y qu√° l√¢u
```bash
# Gi·∫£m limit
curl -X POST "http://localhost:7777/api/orchestrator/quick-update?limit=50"
```

## üìå Best Practices

1. **Quick updates h√†ng ng√†y** - X·ª≠ l√Ω data m·ªõi nhanh
2. **Full pipeline h√†ng tu·∫ßn** - ƒê·∫£m b·∫£o consistency
3. **Check status tr∆∞·ªõc** - Bi·∫øt c√≥ bao nhi√™u pending
4. **Background mode** - Kh√¥ng block API cho tasks l·ªõn
5. **Logs monitoring** - Lu√¥n check logs ƒë·ªÉ catch errors s·ªõm
