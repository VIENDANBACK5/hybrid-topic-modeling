#!/usr/bin/env python3
"""
LLM Extract cho: CH·ªà S·ªê S·∫¢N XU·∫§T C√îNG NGHI·ªÜP C·∫§P T·ªàNH (PII - Provincial Industrial Index)

THU·∫¶N LLM - Kh√¥ng d√πng Regex

Ngu·ªìn d·ªØ li·ªáu:
  - B·∫£ng: important_posts
  - Filter: Posts c√≥ th√¥ng tin v·ªÅ s·∫£n xu·∫•t c√¥ng nghi·ªáp, IIP
  
B·∫£ng ƒë√≠ch:
  - pii_detail - C√°c ch·ªâ s·ªë v·ªÅ s·∫£n xu·∫•t c√¥ng nghi·ªáp, IIP, c√°c ng√†nh c√¥ng nghi·ªáp
"""

import os
import sys
import json
import time
import logging
import requests
from datetime import datetime
from typing import Dict, List, Optional
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# Import SessionLocal
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from app.core.database import SessionLocal

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('call_llm/pii_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:7777")
LLM_API_KEY = os.getenv("OPENROUTER_API_KEY") or os.getenv("OPENAI_API_KEY", "")
LLM_MODEL = os.getenv("LLM_MODEL", "openai/gpt-4o-mini")
BATCH_SIZE = int(os.getenv("BATCH_SIZE", "50"))
DELAY_BETWEEN_CALLS = float(os.getenv("DELAY_BETWEEN_CALLS", "1"))


def call_llm(prompt: str, max_retries: int = 3) -> Optional[str]:
    """Call OpenRouter LLM API"""
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": API_BASE_URL,
        "X-Title": "PII Data Extractor"
    }
    
    payload = {
        "model": LLM_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1,
        "max_tokens": 3000
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            logger.warning(f"LLM call attempt {attempt + 1}/{max_retries} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return None


def save_to_pii(db, data: Dict) -> bool:
    """Save to pii_detail"""
    try:
        # Build period string
        period_parts = []
        if data.get('year'):
            period_parts.append(f"NƒÉm {data['year']}")
        if data.get('quarter'):
            period_parts.append(f"Qu√Ω {data['quarter']}")
        if data.get('month'):
            period_parts.append(f"Th√°ng {data['month']}")
        data['period'] = ", ".join(period_parts) if period_parts else None
        
        # Ensure all fields exist in data dict with None default
        required_fields = [
            'province', 'source_post_id', 'source_url', 'period', 'year', 'quarter', 'month',
            'pii_overall', 'pii_growth_rate', 'industrial_output_value',
            'mining_index', 'mining_output', 'mining_growth',
            'manufacturing_index', 'manufacturing_output', 'manufacturing_growth',
            'electricity_index', 'electricity_output', 'electricity_growth',
            'water_waste_index', 'water_waste_output', 'water_waste_growth',
            'food_processing_index', 'food_processing_output',
            'textile_index', 'textile_output',
            'leather_footwear_index', 'leather_footwear_output',
            'wood_products_index', 'wood_products_output',
            'chemical_index', 'chemical_output',
            'rubber_plastic_index', 'rubber_plastic_output',
            'metal_index', 'metal_output',
            'electronics_index', 'electronics_output',
            'electrical_equipment_index', 'electrical_equipment_output',
            'vehicle_index', 'vehicle_output',
            'state_owned_pii', 'private_pii', 'fdi_pii',
            'state_owned_output', 'private_output', 'fdi_output',
            'manufacturing_share', 'hightech_industry_share', 'supporting_industry_share',
            'labor_productivity', 'capacity_utilization', 'output_per_enterprise',
            'steel_production', 'cement_production', 'fertilizer_production', 'electricity_production',
            'industrial_enterprises', 'large_enterprises', 'sme_industrial',
            'industrial_workers', 'skilled_workers', 'average_wage_industrial',
            'notes', 'data_source', 'extraction_metadata'
        ]
        for field in required_fields:
            if field not in data:
                data[field] = None
        
        insert_query = text("""
            INSERT INTO pii_detail (
                province, source_post_id, source_url, period, year, quarter, month,
                pii_overall, pii_growth_rate, industrial_output_value,
                mining_index, mining_output, mining_growth,
                manufacturing_index, manufacturing_output, manufacturing_growth,
                electricity_index, electricity_output, electricity_growth,
                water_waste_index, water_waste_output, water_waste_growth,
                food_processing_index, food_processing_output,
                textile_index, textile_output,
                leather_footwear_index, leather_footwear_output,
                wood_products_index, wood_products_output,
                chemical_index, chemical_output,
                rubber_plastic_index, rubber_plastic_output,
                metal_index, metal_output,
                electronics_index, electronics_output,
                electrical_equipment_index, electrical_equipment_output,
                vehicle_index, vehicle_output,
                state_owned_pii, private_pii, fdi_pii,
                state_owned_output, private_output, fdi_output,
                manufacturing_share, hightech_industry_share, supporting_industry_share,
                labor_productivity, capacity_utilization, output_per_enterprise,
                steel_production, cement_production, fertilizer_production, electricity_production,
                industrial_enterprises, large_enterprises, sme_industrial,
                industrial_workers, skilled_workers, average_wage_industrial,
                notes, data_source, extraction_metadata
            ) VALUES (
                :province, :source_post_id, :source_url, :period, :year, :quarter, :month,
                :pii_overall, :pii_growth_rate, :industrial_output_value,
                :mining_index, :mining_output, :mining_growth,
                :manufacturing_index, :manufacturing_output, :manufacturing_growth,
                :electricity_index, :electricity_output, :electricity_growth,
                :water_waste_index, :water_waste_output, :water_waste_growth,
                :food_processing_index, :food_processing_output,
                :textile_index, :textile_output,
                :leather_footwear_index, :leather_footwear_output,
                :wood_products_index, :wood_products_output,
                :chemical_index, :chemical_output,
                :rubber_plastic_index, :rubber_plastic_output,
                :metal_index, :metal_output,
                :electronics_index, :electronics_output,
                :electrical_equipment_index, :electrical_equipment_output,
                :vehicle_index, :vehicle_output,
                :state_owned_pii, :private_pii, :fdi_pii,
                :state_owned_output, :private_output, :fdi_output,
                :manufacturing_share, :hightech_industry_share, :supporting_industry_share,
                :labor_productivity, :capacity_utilization, :output_per_enterprise,
                :steel_production, :cement_production, :fertilizer_production, :electricity_production,
                :industrial_enterprises, :large_enterprises, :sme_industrial,
                :industrial_workers, :skilled_workers, :average_wage_industrial,
                :notes, :data_source, :extraction_metadata
            )
        """)
        db.execute(insert_query, data)
        db.commit()
        return True
    except Exception as e:
        logger.error(f"L·ªói save pii_detail: {e}")
        db.rollback()
        return False


def get_posts_from_db(limit: int = 100) -> List[Dict]:
    """L·∫•y important_posts c√≥ n·ªôi dung v·ªÅ s·∫£n xu·∫•t c√¥ng nghi·ªáp"""
    try:
        db = SessionLocal()
        query = text("""
            SELECT id, title, content, url, dvhc as province, published_date, type_newspaper
            FROM important_posts
            WHERE type_newspaper = 'economy'
               AND (
                content ILIKE '%s·∫£n xu·∫•t c√¥ng nghi·ªáp%' OR
                content ILIKE '%c√¥ng nghi·ªáp%' OR
                content ILIKE '%ch·∫ø bi·∫øn ch·∫ø t·∫°o%' OR
                content ILIKE '%iip%' OR
                content ILIKE '%khu c√¥ng nghi·ªáp%' OR
                content ILIKE '%doanh nghi·ªáp c√¥ng nghi·ªáp%' OR
                content ILIKE '%gi√° tr·ªã s·∫£n xu·∫•t%' OR
                content ILIKE '%s·∫£n l∆∞·ª£ng%' OR
                content ILIKE '%nƒÉng su·∫•t lao ƒë·ªông%' OR
                content ILIKE '%c√¥ng su·∫•t%'
            )
            ORDER BY id DESC
            LIMIT :limit
        """)
        
        result = db.execute(query, {"limit": limit})
        posts = []
        for row in result:
            posts.append({
                "id": row[0],
                "title": row[1],
                "content": row[2],
                "url": row[3],
                "province": row[4],
                "published_date": row[5],
                "type_newspaper": row[6]
            })
        
        db.close()
        logger.info(f"L·∫•y ƒë∆∞·ª£c {len(posts)} posts v·ªÅ s·∫£n xu·∫•t c√¥ng nghi·ªáp t·ª´ DB")
        return posts
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y posts t·ª´ DB: {e}")
        return []


def extract_pii_data(content: str, url: str, post_id: int, province: str) -> Optional[Dict]:
    """Extract ch·ªâ s·ªë s·∫£n xu·∫•t c√¥ng nghi·ªáp t·ª´ vƒÉn b·∫£n"""
    prompt = f"""Ph√¢n t√≠ch vƒÉn b·∫£n v√† tr√≠ch xu·∫•t c√°c ch·ªâ s·ªë S·∫¢N XU·∫§T C√îNG NGHI·ªÜP (PII/IIP).

Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c (c√≥ th·ªÉ b·ªè tr·ªëng nhi·ªÅu field):
{{
  "location": null,
  "year": null,
  "quarter": null,
  "month": null,
  "pii_overall": null,
  "pii_growth_rate": null,
  "industrial_output_value": null,
  "mining_index": null,
  "mining_output": null,
  "mining_growth": null,
  "manufacturing_index": null,
  "manufacturing_output": null,
  "manufacturing_growth": null,
  "electricity_index": null,
  "electricity_output": null,
  "electricity_growth": null,
  "water_waste_index": null,
  "water_waste_output": null,
  "water_waste_growth": null,
  "food_processing_index": null,
  "food_processing_output": null,
  "textile_index": null,
  "textile_output": null,
  "leather_footwear_index": null,
  "leather_footwear_output": null,
  "wood_products_index": null,
  "wood_products_output": null,
  "chemical_index": null,
  "chemical_output": null,
  "rubber_plastic_index": null,
  "rubber_plastic_output": null,
  "metal_index": null,
  "metal_output": null,
  "electronics_index": null,
  "electronics_output": null,
  "electrical_equipment_index": null,
  "electrical_equipment_output": null,
  "vehicle_index": null,
  "vehicle_output": null,
  "state_owned_pii": null,
  "private_pii": null,
  "fdi_pii": null,
  "state_owned_output": null,
  "private_output": null,
  "fdi_output": null,
  "manufacturing_share": null,
  "hightech_industry_share": null,
  "supporting_industry_share": null,
  "labor_productivity": null,
  "capacity_utilization": null,
  "output_per_enterprise": null,
  "steel_production": null,
  "cement_production": null,
  "fertilizer_production": null,
  "electricity_production": null,
  "industrial_enterprises": null,
  "large_enterprises": null,
  "sme_industrial": null,
  "industrial_workers": null,
  "skilled_workers": null,
  "average_wage_industrial": null,
  "notes": null
}}

Gi·∫£i th√≠ch c√°c tr∆∞·ªùng (KH√îNG C·∫¶N ƒê·∫¶Y ƒê·ª¶ - ch·ªâ extract khi c√≥ trong vƒÉn b·∫£n):
- location (string): T√™n ƒë·ªãa ph∆∞∆°ng
- year/quarter/month (int): Th·ªùi gian
- pii_overall (float): Ch·ªâ s·ªë IIP t·ªïng h·ª£p (Index, base=100)
- pii_growth_rate (float): T·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng IIP (%)
- industrial_output_value (float): Gi√° tr·ªã s·∫£n xu·∫•t c√¥ng nghi·ªáp (t·ª∑ VNƒê)
- mining_* : Ch·ªâ s·ªë v√† s·∫£n l∆∞·ª£ng khai kho√°ng
- manufacturing_* : Ch·ªâ s·ªë v√† s·∫£n l∆∞·ª£ng c√¥ng nghi·ªáp ch·∫ø bi·∫øn
- electricity_* : Ch·ªâ s·ªë v√† s·∫£n l∆∞·ª£ng ƒëi·ªán, kh√≠ ƒë·ªët, n∆∞·ªõc
- water_waste_* : Ch·ªâ s·ªë c·∫•p n∆∞·ªõc, x·ª≠ l√Ω r√°c
- food_processing_* : Ch·∫ø bi·∫øn th·ª±c ph·∫©m
- textile_* : D·ªát may
- leather_footwear_* : Da gi√†y
- wood_products_* : G·ªó v√† s·∫£n ph·∫©m g·ªó
- chemical_* : H√≥a ch·∫•t
- rubber_plastic_* : Cao su v√† plastic
- metal_* : Kim lo·∫°i
- electronics_* : ƒêi·ªán t·ª≠, m√°y t√≠nh
- electrical_equipment_* : Thi·∫øt b·ªã ƒëi·ªán
- vehicle_* : Ph∆∞∆°ng ti·ªán v·∫≠n t·∫£i
- state_owned_* : Khu v·ª±c nh√† n∆∞·ªõc
- private_* : Khu v·ª±c t∆∞ nh√¢n
- fdi_* : Khu v·ª±c FDI
- manufacturing_share (float): T·ª∑ tr·ªçng ch·∫ø bi·∫øn ch·∫ø t·∫°o (%)
- hightech_industry_share (float): T·ª∑ tr·ªçng c√¥ng nghi·ªáp c√¥ng ngh·ªá cao (%)
- supporting_industry_share (float): T·ª∑ tr·ªçng c√¥ng nghi·ªáp h·ªó tr·ª£ (%)
- labor_productivity (float): NƒÉng su·∫•t lao ƒë·ªông (tri·ªáu VNƒê/ng∆∞·ªùi)
- capacity_utilization (float): T·ª∑ l·ªá s·ª≠ d·ª•ng c√¥ng su·∫•t (%)
- output_per_enterprise (float): S·∫£n l∆∞·ª£ng b√¨nh qu√¢n/DN (t·ª∑ VNƒê)
- steel_production (float): S·∫£n l∆∞·ª£ng th√©p (ngh√¨n t·∫•n)
- cement_production (float): S·∫£n l∆∞·ª£ng xi mƒÉng (ngh√¨n t·∫•n)
- fertilizer_production (float): S·∫£n l∆∞·ª£ng ph√¢n b√≥n (ngh√¨n t·∫•n)
- electricity_production (float): S·∫£n l∆∞·ª£ng ƒëi·ªán (tri·ªáu kWh)
- industrial_enterprises (int): S·ªë doanh nghi·ªáp c√¥ng nghi·ªáp
- large_enterprises (int): S·ªë DN c√¥ng nghi·ªáp l·ªõn
- sme_industrial (int): S·ªë DN c√¥ng nghi·ªáp v·ª´a v√† nh·ªè
- industrial_workers (int): S·ªë lao ƒë·ªông trong c√¥ng nghi·ªáp
- skilled_workers (int): S·ªë lao ƒë·ªông c√≥ tay ngh·ªÅ
- average_wage_industrial (float): L∆∞∆°ng b√¨nh qu√¢n c√¥ng nghi·ªáp (tri·ªáu VNƒê)
- notes (string): Th√¥ng tin b·ªï sung

QUY T·∫ÆC:
1. LINH HO·∫†T: Extract B·∫§T K·ª≤ ch·ªâ s·ªë C√îNG NGHI·ªÜP n√†o (kh√¥ng c·∫ßn ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ fields)
2. C√°c t·ª´ kh√≥a c·∫ßn ch√∫ √Ω:
   - S·∫£n xu·∫•t c√¥ng nghi·ªáp, gi√° tr·ªã s·∫£n xu·∫•t, ch·ªâ s·ªë IIP
   - TƒÉng tr∆∞·ªüng c√¥ng nghi·ªáp, t·ªëc ƒë·ªô tƒÉng tr∆∞·ªüng
   - C√°c ng√†nh: khai kho√°ng, ch·∫ø bi·∫øn ch·∫ø t·∫°o, ƒëi·ªán, d·ªát may, da gi√†y, g·ªó, h√≥a ch·∫•t, ƒëi·ªán t·ª≠, √¥ t√¥...
   - Khu v·ª±c: nh√† n∆∞·ªõc, t∆∞ nh√¢n, FDI
   - Doanh nghi·ªáp c√¥ng nghi·ªáp, lao ƒë·ªông c√¥ng nghi·ªáp
   - NƒÉng su·∫•t lao ƒë·ªông, c√¥ng su·∫•t
   - S·∫£n l∆∞·ª£ng: th√©p, xi mƒÉng, ph√¢n b√≥n, ƒëi·ªán
3. üìà Ch·ªâ s·ªë IIP:
   - Ch·ªâ s·ªë IIP th∆∞·ªùng c√≥ base=100
   - TƒÉng tr∆∞·ªüng th∆∞·ªùng t√≠nh so v·ªõi c√πng k·ª≥ nƒÉm tr∆∞·ªõc (%)
4. Nh·∫≠n di·ªán ƒë·ªãa ƒëi·ªÉm: Tr√≠ch xu·∫•t t√™n t·ªânh/th√†nh/huy·ªán/x√£ t·ª´ vƒÉn b·∫£n
5. ‚è∞ Th·ªùi gian:
   - "Qu√Ω I/II/III/IV" ‚Üí quarter=1/2/3/4
   - "6 th√°ng ƒë·∫ßu nƒÉm" ‚Üí quarter=2
   - "9 th√°ng" ‚Üí quarter=3
   - "NƒÉm 2024" ‚Üí year=2024
6. CH·ªà tr·∫£ v·ªÅ {{"no_data": true}} n·∫øu vƒÉn b·∫£n HO√ÄN TO√ÄN KH√îNG c√≥ ch·ªâ s·ªë c√¥ng nghi·ªáp

VƒÉn b·∫£n:
\"\"\"
{content[:4000]}
\"\"\"

Ch·ªâ tr·∫£ v·ªÅ JSON."""

    try:
        result = call_llm(prompt)
        if not result:
            return None
        
        json_start = result.find("{")
        json_end = result.rfind("}") + 1
        if json_start == -1:
            return None
        
        data = json.loads(result[json_start:json_end])
        
        if data.get("no_data"):
            return None
        
        # Set province from location or use default
        location = data.pop("location", None)
        if location:
            data["province"] = location
        else:
            data["province"] = province
        
        data["source_post_id"] = post_id
        data["source_url"] = url if url and url.startswith("http") else None
        data["data_source"] = "LLM Extraction"
        data["extraction_metadata"] = json.dumps({"model": LLM_MODEL, "timestamp": datetime.now().isoformat()})
        
        return data
        
    except Exception as e:
        logger.error(f"L·ªói extract PII: {e}")
        return None


def process_post(post: Dict, db) -> int:
    """X·ª≠ l√Ω 1 post - Extract PII"""
    post_id = post.get("id")
    content = post.get("content", "")
    title = post.get("title", "")
    province = post.get("province", "H∆∞ng Y√™n")
    url = post.get("url") or None
    
    logger.info(f"\n{'='*60}")
    logger.info(f"Post ID: {post_id}")
    logger.info(f"Title: {title[:100]}")
    
    data = extract_pii_data(content, url, post_id, province)
    if data:
        if save_to_pii(db, data):
            logger.info(f"Saved to pii_detail")
            return 1
        else:
            logger.error(f"Failed to save pii_detail")
    
    return 0


def main():
    """Main function"""
    logger.info("="*80)
    logger.info("B·∫ÆT ƒê·∫¶U LLM EXTRACTION - CH·ªà S·ªê S·∫¢N XU·∫§T C√îNG NGHI·ªÜP (PII)")
    logger.info(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("="*80)
    
    db = SessionLocal()
    try:
        posts = get_posts_from_db(limit=BATCH_SIZE)
        
        if not posts:
            return {
                "status": "no_data",
                "message": "Kh√¥ng c√≥ posts v·ªÅ s·∫£n xu·∫•t c√¥ng nghi·ªáp",
                "processed": 0
            }
        
        total_extracted = 0
        
        for i, post in enumerate(posts, 1):
            logger.info(f"\nProgress: {i}/{len(posts)}")
            try:
                total_extracted += process_post(post, db)
                time.sleep(DELAY_BETWEEN_CALLS)
            except Exception as e:
                logger.error(f"L·ªói: {e}")
        
        logger.info("\n" + "="*80)
        logger.info(f"ƒê√£ x·ª≠ l√Ω: {len(posts)} posts")
        logger.info(f"Extracted: {total_extracted} records")
        logger.info("="*80)
        
        return {
            "status": "success",
            "processed": len(posts),
            "extracted": total_extracted
        }
    finally:
        db.close()


if __name__ == "__main__":
    main()
