#!/usr/bin/env python3
"""
LLM Extract cho: THU H√öT ƒê·∫¶U T∆Ø TR·ª∞C TI·∫æP N∆Ø·ªöC NGO√ÄI (FDI)

THU·∫¶N LLM - Kh√¥ng d√πng Regex

Ngu·ªìn d·ªØ li·ªáu:
  - B·∫£ng: important_posts
  - Filter: Posts c√≥ th√¥ng tin v·ªÅ FDI, ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i
  
B·∫£ng ƒë√≠ch:
  - fdi_detail - C√°c ch·ªâ s·ªë v·ªÅ v·ªën FDI, d·ª± √°n, ng√†nh ngh·ªÅ, qu·ªëc gia ƒë·∫ßu t∆∞
"""

import os
import sys
import json
import time
import logging
import requests
from datetime import datetime
from typing import Dict, List, Optional
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# Import SessionLocal
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from app.core.database import SessionLocal

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('call_llm/fdi_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:7777")
LLM_API_KEY = os.getenv("OPENROUTER_API_KEY") or os.getenv("OPENAI_API_KEY", "")
LLM_MODEL = os.getenv("LLM_MODEL", "openai/gpt-4o-mini")
BATCH_SIZE = int(os.getenv("BATCH_SIZE", "50"))
DELAY_BETWEEN_CALLS = float(os.getenv("DELAY_BETWEEN_CALLS", "1"))


def call_llm(prompt: str, max_retries: int = 3) -> Optional[str]:
    """Call OpenRouter LLM API"""
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": API_BASE_URL,
        "X-Title": "FDI Data Extractor"
    }
    
    payload = {
        "model": LLM_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1,
        "max_tokens": 3000
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            logger.warning(f"LLM call attempt {attempt + 1}/{max_retries} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return None


def save_to_fdi(db, data: Dict) -> bool:
    """Save to fdi_detail"""
    try:
        # Build period string
        period_parts = []
        if data.get('year'):
            period_parts.append(f"NƒÉm {data['year']}")
        if data.get('quarter'):
            period_parts.append(f"Qu√Ω {data['quarter']}")
        if data.get('month'):
            period_parts.append(f"Th√°ng {data['month']}")
        data['period'] = ", ".join(period_parts) if period_parts else None
        
        # Ensure all fields exist in data dict with None default
        required_fields = [
            'province', 'source_post_id', 'source_url', 'period', 'year', 'quarter', 'month',
            'registered_capital', 'new_projects_capital', 'additional_capital', 'capital_contribution',
            'disbursed_capital', 'disbursement_rate', 'accumulated_disbursement',
            'total_projects', 'new_projects', 'adjusted_projects', 'share_purchase_projects',
            'manufacturing_fdi', 'realestate_fdi', 'retail_fdi', 'construction_fdi',
            'technology_fdi', 'energy_fdi', 'agriculture_fdi',
            'japan_fdi', 'korea_fdi', 'singapore_fdi', 'china_fdi', 'taiwan_fdi', 'hongkong_fdi',
            'europe_fdi', 'us_fdi', 'other_countries_fdi',
            'fdi_export_value', 'fdi_import_value', 'fdi_trade_surplus', 'fdi_sector_employees',
            'fdi_gdp_contribution', 'fdi_revenue_to_budget', 'fdi_share_in_industry', 'fdi_share_in_exports',
            'notes', 'data_source', 'extraction_metadata'
        ]
        for field in required_fields:
            if field not in data:
                data[field] = None
        
        insert_query = text("""
            INSERT INTO fdi_detail (
                province, source_post_id, source_url, period, year, quarter, month,
                registered_capital, new_projects_capital, additional_capital, capital_contribution,
                disbursed_capital, disbursement_rate, accumulated_disbursement,
                total_projects, new_projects, adjusted_projects, share_purchase_projects,
                manufacturing_fdi, realestate_fdi, retail_fdi, construction_fdi, 
                technology_fdi, energy_fdi, agriculture_fdi,
                japan_fdi, korea_fdi, singapore_fdi, china_fdi, taiwan_fdi, 
                hongkong_fdi, thailand_fdi, usa_fdi, eu_fdi,
                wholly_owned_fdi, joint_venture_fdi, bcc_fdi,
                fdi_contribution_grdp, fdi_export_value, fdi_export_share, 
                fdi_employment, fdi_tax_revenue,
                industrial_zones, economic_zones, occupancy_rate,
                fortune500_investors, high_tech_projects,
                notes, data_source, extraction_metadata
            ) VALUES (
                :province, :source_post_id, :source_url, :period, :year, :quarter, :month,
                :registered_capital, :new_projects_capital, :additional_capital, :capital_contribution,
                :disbursed_capital, :disbursement_rate, :accumulated_disbursement,
                :total_projects, :new_projects, :adjusted_projects, :share_purchase_projects,
                :manufacturing_fdi, :realestate_fdi, :retail_fdi, :construction_fdi, 
                :technology_fdi, :energy_fdi, :agriculture_fdi,
                :japan_fdi, :korea_fdi, :singapore_fdi, :china_fdi, :taiwan_fdi, 
                :hongkong_fdi, :thailand_fdi, :usa_fdi, :eu_fdi,
                :wholly_owned_fdi, :joint_venture_fdi, :bcc_fdi,
                :fdi_contribution_grdp, :fdi_export_value, :fdi_export_share, 
                :fdi_employment, :fdi_tax_revenue,
                :industrial_zones, :economic_zones, :occupancy_rate,
                :fortune500_investors, :high_tech_projects,
                :notes, :data_source, :extraction_metadata
            )
        """)
        db.execute(insert_query, data)
        db.commit()
        return True
    except Exception as e:
        logger.error(f"L·ªói save fdi_detail: {e}")
        db.rollback()
        return False


def get_posts_from_db(limit: int = 100) -> List[Dict]:
    """L·∫•y important_posts c√≥ n·ªôi dung v·ªÅ FDI"""
    try:
        db = SessionLocal()
        query = text("""
            SELECT id, title, content, url, dvhc as province, published_date, type_newspaper
            FROM important_posts
            WHERE type_newspaper = 'economy'
               AND (
                content ILIKE '%fdi%' OR
                content ILIKE '%ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i%' OR
                content ILIKE '%ƒë·∫ßu t∆∞ tr·ª±c ti·∫øp%' OR
                content ILIKE '%v·ªën n∆∞·ªõc ngo√†i%' OR
                content ILIKE '%d·ª± √°n fdi%' OR
                content ILIKE '%khu c√¥ng nghi·ªáp%' OR
                content ILIKE '%khu kinh t·∫ø%' OR
                content ILIKE '%nh√† ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i%' OR
                content ILIKE '%gi·∫£i ng√¢n%' OR
                content ILIKE '%c·∫•p ph√©p ƒë·∫ßu t∆∞%'
            )
            ORDER BY id DESC
            LIMIT :limit
        """)
        
        result = db.execute(query, {"limit": limit})
        posts = []
        for row in result:
            posts.append({
                "id": row[0],
                "title": row[1],
                "content": row[2],
                "url": row[3],
                "province": row[4],
                "published_date": row[5],
                "type_newspaper": row[6]
            })
        
        db.close()
        logger.info(f"L·∫•y ƒë∆∞·ª£c {len(posts)} posts v·ªÅ FDI t·ª´ DB")
        return posts
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y posts t·ª´ DB: {e}")
        return []


def extract_fdi_data(content: str, url: str, post_id: int, province: str) -> Optional[Dict]:
    """Extract ch·ªâ s·ªë FDI t·ª´ vƒÉn b·∫£n"""
    prompt = f"""Ph√¢n t√≠ch vƒÉn b·∫£n v√† tr√≠ch xu·∫•t c√°c ch·ªâ s·ªë THU H√öT FDI (ƒê·∫ßu t∆∞ Tr·ª±c ti·∫øp N∆∞·ªõc ngo√†i).

Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c:
{{
  "location": null,
  "year": null,
  "quarter": null,
  "month": null,
  "registered_capital": null,
  "new_projects_capital": null,
  "additional_capital": null,
  "capital_contribution": null,
  "disbursed_capital": null,
  "disbursement_rate": null,
  "accumulated_disbursement": null,
  "total_projects": null,
  "new_projects": null,
  "adjusted_projects": null,
  "share_purchase_projects": null,
  "manufacturing_fdi": null,
  "realestate_fdi": null,
  "retail_fdi": null,
  "construction_fdi": null,
  "technology_fdi": null,
  "energy_fdi": null,
  "agriculture_fdi": null,
  "japan_fdi": null,
  "korea_fdi": null,
  "singapore_fdi": null,
  "china_fdi": null,
  "taiwan_fdi": null,
  "hongkong_fdi": null,
  "thailand_fdi": null,
  "usa_fdi": null,
  "eu_fdi": null,
  "wholly_owned_fdi": null,
  "joint_venture_fdi": null,
  "bcc_fdi": null,
  "fdi_contribution_grdp": null,
  "fdi_export_value": null,
  "fdi_export_share": null,
  "fdi_employment": null,
  "fdi_tax_revenue": null,
  "industrial_zones": null,
  "economic_zones": null,
  "occupancy_rate": null,
  "fortune500_investors": null,
  "high_tech_projects": null,
  "notes": null
}}

Gi·∫£i th√≠ch c√°c tr∆∞·ªùng:
- location (string): T√™n ƒë·ªãa ph∆∞∆°ng (t·ªânh/th√†nh/huy·ªán/x√£)
- year/quarter/month (int): Th·ªùi gian
- registered_capital (float): V·ªën FDI ƒëƒÉng k√Ω (tri·ªáu USD)
- new_projects_capital (float): V·ªën ƒëƒÉng k√Ω d·ª± √°n m·ªõi (tri·ªáu USD)
- additional_capital (float): V·ªën ƒëƒÉng k√Ω tƒÉng th√™m (tri·ªáu USD)
- capital_contribution (float): V·ªën g√≥p mua c·ªï ph·∫ßn (tri·ªáu USD)
- disbursed_capital (float): V·ªën FDI gi·∫£i ng√¢n (tri·ªáu USD)
- disbursement_rate (float): T·ª∑ l·ªá gi·∫£i ng√¢n so v·ªõi ƒëƒÉng k√Ω (%)
- accumulated_disbursement (float): V·ªën gi·∫£i ng√¢n l≈©y k·∫ø (tri·ªáu USD)
- total_projects (int): T·ªïng s·ªë d·ª± √°n (m·ªõi + tƒÉng v·ªën + g√≥p v·ªën)
- new_projects (int): S·ªë d·ª± √°n ƒë·∫ßu t∆∞ m·ªõi
- adjusted_projects (int): S·ªë l∆∞·ª£t d·ª± √°n tƒÉng v·ªën
- share_purchase_projects (int): S·ªë l∆∞·ª£t g√≥p v·ªën mua c·ªï ph·∫ßn
- manufacturing_fdi (float): FDI v√†o s·∫£n xu·∫•t ch·∫ø bi·∫øn (tri·ªáu USD)
- realestate_fdi (float): FDI v√†o b·∫•t ƒë·ªông s·∫£n (tri·ªáu USD)
- retail_fdi (float): FDI v√†o b√°n l·∫ª (tri·ªáu USD)
- construction_fdi (float): FDI v√†o x√¢y d·ª±ng (tri·ªáu USD)
- technology_fdi (float): FDI v√†o CNTT (tri·ªáu USD)
- energy_fdi (float): FDI v√†o ƒëi·ªán, kh√≠ ƒë·ªët, n∆∞·ªõc (tri·ªáu USD)
- agriculture_fdi (float): FDI v√†o n√¥ng l√¢m ng∆∞ nghi·ªáp (tri·ªáu USD)
- japan_fdi (float): FDI t·ª´ Nh·∫≠t B·∫£n (tri·ªáu USD)
- korea_fdi (float): FDI t·ª´ H√†n Qu·ªëc (tri·ªáu USD)
- singapore_fdi (float): FDI t·ª´ Singapore (tri·ªáu USD)
- china_fdi (float): FDI t·ª´ Trung Qu·ªëc (tri·ªáu USD)
- taiwan_fdi (float): FDI t·ª´ ƒê√†i Loan (tri·ªáu USD)
- hongkong_fdi (float): FDI t·ª´ H·ªìng K√¥ng (tri·ªáu USD)
- thailand_fdi (float): FDI t·ª´ Th√°i Lan (tri·ªáu USD)
- usa_fdi (float): FDI t·ª´ Hoa K·ª≥ (tri·ªáu USD)
- eu_fdi (float): FDI t·ª´ EU (tri·ªáu USD)
- wholly_owned_fdi (float): FDI 100% v·ªën n∆∞·ªõc ngo√†i (tri·ªáu USD)
- joint_venture_fdi (float): FDI li√™n doanh (tri·ªáu USD)
- bcc_fdi (float): FDI h·ª£p ƒë·ªìng h·ª£p t√°c kinh doanh (tri·ªáu USD)
- fdi_contribution_grdp (float): ƒê√≥ng g√≥p FDI v√†o GRDP (%)
- fdi_export_value (float): Gi√° tr·ªã xu·∫•t kh·∫©u t·ª´ FDI (tri·ªáu USD)
- fdi_export_share (float): T·ª∑ tr·ªçng xu·∫•t kh·∫©u FDI/t·ªïng XK (%)
- fdi_employment (int): S·ªë lao ƒë·ªông trong khu v·ª±c FDI (ng∆∞·ªùi)
- fdi_tax_revenue (float): Thu ng√¢n s√°ch t·ª´ FDI (t·ª∑ VNƒê)
- industrial_zones (int): S·ªë khu c√¥ng nghi·ªáp c√≥ FDI
- economic_zones (int): S·ªë khu kinh t·∫ø c√≥ FDI
- occupancy_rate (float): T·ª∑ l·ªá l·∫•p ƒë·∫ßy KCN/KKT (%)
- fortune500_investors (int): S·ªë nh√† ƒë·∫ßu t∆∞ Fortune 500
- high_tech_projects (int): S·ªë d·ª± √°n c√¥ng ngh·ªá cao
- notes (string): Th√¥ng tin b·ªï sung

QUY T·∫ÆC:
1. LINH HO·∫†T: Extract B·∫§T K·ª≤ ch·ªâ s·ªë FDI n√†o (kh√¥ng c·∫ßn ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ fields)
2. C√°c t·ª´ kh√≥a c·∫ßn ch√∫ √Ω:
   - V·ªën FDI, v·ªën ƒëƒÉng k√Ω, v·ªën gi·∫£i ng√¢n, v·ªën ƒë·∫ßu t∆∞ n∆∞·ªõc ngo√†i
   - D·ª± √°n FDI, d·ª± √°n m·ªõi, tƒÉng v·ªën, g√≥p v·ªën mua c·ªï ph·∫ßn
   - Nh√† ƒë·∫ßu t∆∞: Nh·∫≠t B·∫£n, H√†n Qu·ªëc, Singapore, Trung Qu·ªëc, ƒê√†i Loan, etc.
   - Ng√†nh: s·∫£n xu·∫•t, b·∫•t ƒë·ªông s·∫£n, x√¢y d·ª±ng, c√¥ng ngh·ªá, nƒÉng l∆∞·ª£ng
   - Khu c√¥ng nghi·ªáp, khu kinh t·∫ø, KCN, KKT
   - Xu·∫•t kh·∫©u FDI, lao ƒë·ªông FDI, thu ng√¢n s√°ch t·ª´ FDI
3. üí∞ ƒê∆°n v·ªã: 
   - V·ªën FDI th∆∞·ªùng t√≠nh b·∫±ng tri·ªáu USD
   - Thu ng√¢n s√°ch t√≠nh b·∫±ng t·ª∑ VNƒê
4. Nh·∫≠n di·ªán ƒë·ªãa ƒëi·ªÉm: Tr√≠ch xu·∫•t t√™n t·ªânh/th√†nh/huy·ªán/x√£ t·ª´ vƒÉn b·∫£n
5. ‚è∞ Th·ªùi gian:
   - "Qu√Ω I/II/III/IV" ‚Üí quarter=1/2/3/4
   - "6 th√°ng ƒë·∫ßu nƒÉm" ‚Üí quarter=2
   - "9 th√°ng" ‚Üí quarter=3
   - "NƒÉm 2024" ‚Üí year=2024
6. CH·ªà tr·∫£ v·ªÅ {{"no_data": true}} n·∫øu vƒÉn b·∫£n HO√ÄN TO√ÄN KH√îNG c√≥ ch·ªâ s·ªë FDI

VƒÉn b·∫£n:
\"\"\"
{content[:4000]}
\"\"\"

Ch·ªâ tr·∫£ v·ªÅ JSON."""

    try:
        result = call_llm(prompt)
        if not result:
            return None
        
        json_start = result.find("{")
        json_end = result.rfind("}") + 1
        if json_start == -1:
            return None
        
        data = json.loads(result[json_start:json_end])
        
        if data.get("no_data"):
            return None
        
        # Set province from location or use default
        location = data.pop("location", None)
        if location:
            data["province"] = location
        else:
            data["province"] = province
        
        data["source_post_id"] = post_id
        data["source_url"] = url if url and url.startswith("http") else None
        data["data_source"] = "LLM Extraction"
        data["extraction_metadata"] = json.dumps({"model": LLM_MODEL, "timestamp": datetime.now().isoformat()})
        
        return data
        
    except Exception as e:
        logger.error(f"L·ªói extract FDI: {e}")
        return None


def process_post(post: Dict, db) -> int:
    """X·ª≠ l√Ω 1 post - Extract FDI"""
    post_id = post.get("id")
    content = post.get("content", "")
    title = post.get("title", "")
    province = post.get("province", "H∆∞ng Y√™n")
    url = post.get("url") or None
    
    logger.info(f"\n{'='*60}")
    logger.info(f"Post ID: {post_id}")
    logger.info(f"Title: {title[:100]}")
    
    data = extract_fdi_data(content, url, post_id, province)
    if data:
        if save_to_fdi(db, data):
            logger.info(f"Saved to fdi_detail")
            return 1
        else:
            logger.error(f"Failed to save fdi_detail")
    
    return 0


def main():
    """Main function"""
    logger.info("="*80)
    logger.info("B·∫ÆT ƒê·∫¶U LLM EXTRACTION - THU H√öT FDI")
    logger.info(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("="*80)
    
    db = SessionLocal()
    try:
        posts = get_posts_from_db(limit=BATCH_SIZE)
        
        if not posts:
            return {
                "status": "no_data",
                "message": "Kh√¥ng c√≥ posts v·ªÅ FDI",
                "processed": 0
            }
        
        total_extracted = 0
        
        for i, post in enumerate(posts, 1):
            logger.info(f"\nProgress: {i}/{len(posts)}")
            try:
                total_extracted += process_post(post, db)
                time.sleep(DELAY_BETWEEN_CALLS)
            except Exception as e:
                logger.error(f"L·ªói: {e}")
        
        logger.info("\n" + "="*80)
        logger.info(f"ƒê√£ x·ª≠ l√Ω: {len(posts)} posts")
        logger.info(f"Extracted: {total_extracted} records")
        logger.info("="*80)
        
        return {
            "status": "success",
            "processed": len(posts),
            "extracted": total_extracted
        }
    finally:
        db.close()


if __name__ == "__main__":
    main()
