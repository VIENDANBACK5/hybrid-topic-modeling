#!/usr/bin/env python3
"""
LLM Extract cho: CHUY·ªÇN ƒê·ªîI S·ªê (Digital Transformation)

THU·∫¶N LLM - Kh√¥ng d√πng Regex

Ngu·ªìn d·ªØ li·ªáu:
  - B·∫£ng: important_posts
  - Filter: Posts c√≥ th√¥ng tin v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë, ch√≠nh quy·ªÅn ƒëi·ªán t·ª≠
  
B·∫£ng ƒë√≠ch:
  - digital_transformation_detail - C√°c ch·ªâ s·ªë v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë, e-government, h·∫° t·∫ßng s·ªë
"""

import os
import sys
import json
import time
import logging
import requests
from datetime import datetime
from typing import Dict, List, Optional
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker

# Import SessionLocal
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from app.core.database import SessionLocal

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('call_llm/digital_transformation_extraction.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configuration
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:7777")
LLM_API_KEY = os.getenv("OPENROUTER_API_KEY") or os.getenv("OPENAI_API_KEY", "")
LLM_MODEL = os.getenv("LLM_MODEL", "openai/gpt-4o-mini")
BATCH_SIZE = int(os.getenv("BATCH_SIZE", "50"))
DELAY_BETWEEN_CALLS = float(os.getenv("DELAY_BETWEEN_CALLS", "1"))


def call_llm(prompt: str, max_retries: int = 3) -> Optional[str]:
    """Call OpenRouter LLM API"""
    url = "https://openrouter.ai/api/v1/chat/completions"
    
    headers = {
        "Authorization": f"Bearer {LLM_API_KEY}",
        "Content-Type": "application/json",
        "HTTP-Referer": API_BASE_URL,
        "X-Title": "Digital Transformation Data Extractor"
    }
    
    payload = {
        "model": LLM_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.1,
        "max_tokens": 3000
    }
    
    for attempt in range(max_retries):
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=60)
            response.raise_for_status()
            result = response.json()
            return result["choices"][0]["message"]["content"]
        except Exception as e:
            logger.warning(f"LLM call attempt {attempt + 1}/{max_retries} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)
    return None


def save_to_digital_transformation(db, data: Dict) -> bool:
    """Save to digital_transformation_detail"""
    try:
        # Build period string
        period_parts = []
        if data.get('year'):
            period_parts.append(f"NƒÉm {data['year']}")
        if data.get('quarter'):
            period_parts.append(f"Qu√Ω {data['quarter']}")
        if data.get('month'):
            period_parts.append(f"Th√°ng {data['month']}")
        data['period'] = ", ".join(period_parts) if period_parts else None
        
        # Ensure all fields exist in data dict with None default
        required_fields = [
            'province', 'source_post_id', 'source_url', 'period', 'year', 'quarter', 'month',
            'dx_index', 'dx_readiness_index', 'dx_maturity_level', 'dx_ranking',
            'egov_index', 'online_public_services', 'level3_services', 'level4_services',
            'online_service_usage_rate',
            'government_portals', 'integrated_databases', 'shared_databases', 'data_sharing_rate',
            'cloud_adoption_rate', 'data_centers', 'broadband_coverage', 'fiber_optic_coverage', 'fiveg_coverage',
            'ai_projects', 'iot_devices', 'blockchain_projects', 'smart_city_projects',
            'dx_enterprises', 'dx_adoption_rate', 'digital_platform_usage',
            'dx_training_programs', 'digital_skills_workforce',
            'notes', 'data_source', 'extraction_metadata'
        ]
        for field in required_fields:
            if field not in data:
                data[field] = None
        
        insert_query = text("""
            INSERT INTO digital_transformation_detail (
                province, source_post_id, source_url, period, year, quarter, month,
                dx_index, dx_readiness_index, dx_maturity_level, dx_ranking,
                egov_index, online_public_services, level3_services, level4_services, 
                online_service_usage_rate,
                government_portals, integrated_databases, shared_databases, data_sharing_rate,
                cloud_adoption_rate, data_centers, broadband_coverage, fiber_optic_coverage, fiveg_coverage,
                sme_dx_adoption, large_company_dx_adoption, companies_using_cloud, 
                companies_using_ai, companies_using_iot, companies_using_big_data,
                digital_literacy_rate, digital_skills_workforce, digital_training_programs, 
                people_trained_digital,
                ai_projects, iot_projects, blockchain_projects, smart_city_projects,
                smart_agriculture_area, agricultural_iot_adoption, agricultural_digital_platforms,
                telemedicine_facilities, electronic_health_records_rate, health_digital_platforms,
                notes, data_source, extraction_metadata
            ) VALUES (
                :province, :source_post_id, :source_url, :period, :year, :quarter, :month,
                :dx_index, :dx_readiness_index, :dx_maturity_level, :dx_ranking,
                :egov_index, :online_public_services, :level3_services, :level4_services, 
                :online_service_usage_rate,
                :government_portals, :integrated_databases, :shared_databases, :data_sharing_rate,
                :cloud_adoption_rate, :data_centers, :broadband_coverage, :fiber_optic_coverage, :fiveg_coverage,
                :sme_dx_adoption, :large_company_dx_adoption, :companies_using_cloud, 
                :companies_using_ai, :companies_using_iot, :companies_using_big_data,
                :digital_literacy_rate, :digital_skills_workforce, :digital_training_programs, 
                :people_trained_digital,
                :ai_projects, :iot_projects, :blockchain_projects, :smart_city_projects,
                :smart_agriculture_area, :agricultural_iot_adoption, :agricultural_digital_platforms,
                :telemedicine_facilities, :electronic_health_records_rate, :health_digital_platforms,
                :notes, :data_source, :extraction_metadata
            )
        """)
        db.execute(insert_query, data)
        db.commit()
        return True
    except Exception as e:
        logger.error(f"L·ªói save digital_transformation_detail: {e}")
        db.rollback()
        return False


def get_posts_from_db(limit: int = 100) -> List[Dict]:
    """L·∫•y important_posts c√≥ n·ªôi dung v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë"""
    try:
        db = SessionLocal()
        query = text("""
            SELECT id, title, content, url, dvhc as province, published_date, type_newspaper
            FROM important_posts
            WHERE type_newspaper = 'economy'
               AND (
                content ILIKE '%chuy·ªÉn ƒë·ªïi s·ªë%' OR
                content ILIKE '%cds%' OR
                content ILIKE '%digital transformation%' OR
                content ILIKE '%ch√≠nh quy·ªÅn ƒëi·ªán t·ª≠%' OR
                content ILIKE '%ch√≠nh quy·ªÅn s·ªë%' OR
                content ILIKE '%e-government%' OR
                content ILIKE '%d·ªãch v·ª• c√¥ng tr·ª±c tuy·∫øn%' OR
                content ILIKE '%c·ªïng th√¥ng tin ƒëi·ªán t·ª≠%' OR
                content ILIKE '%h·∫° t·∫ßng s·ªë%' OR
                content ILIKE '%cloud%' OR
                content ILIKE '%ƒëi·ªán to√°n ƒë√°m m√¢y%' OR
                content ILIKE '%smart city%' OR
                content ILIKE '%th√†nh ph·ªë th√¥ng minh%'
            )
            ORDER BY id DESC
            LIMIT :limit
        """)
        
        result = db.execute(query, {"limit": limit})
        posts = []
        for row in result:
            posts.append({
                "id": row[0],
                "title": row[1],
                "content": row[2],
                "url": row[3],
                "province": row[4],
                "published_date": row[5],
                "type_newspaper": row[6]
            })
        
        db.close()
        logger.info(f"L·∫•y ƒë∆∞·ª£c {len(posts)} posts v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë t·ª´ DB")
        return posts
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y posts t·ª´ DB: {e}")
        return []


def extract_digital_transformation_data(content: str, url: str, post_id: int, province: str) -> Optional[Dict]:
    """Extract ch·ªâ s·ªë chuy·ªÉn ƒë·ªïi s·ªë t·ª´ vƒÉn b·∫£n"""
    prompt = f"""Ph√¢n t√≠ch vƒÉn b·∫£n v√† tr√≠ch xu·∫•t c√°c ch·ªâ s·ªë CHUY·ªÇN ƒê·ªîI S·ªê.

Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c:
{{
  "location": null,
  "year": null,
  "quarter": null,
  "month": null,
  "dx_index": null,
  "dx_readiness_index": null,
  "dx_maturity_level": null,
  "dx_ranking": null,
  "egov_index": null,
  "online_public_services": null,
  "level3_services": null,
  "level4_services": null,
  "online_service_usage_rate": null,
  "government_portals": null,
  "integrated_databases": null,
  "shared_databases": null,
  "data_sharing_rate": null,
  "cloud_adoption_rate": null,
  "data_centers": null,
  "broadband_coverage": null,
  "fiber_optic_coverage": null,
  "fiveg_coverage": null,
  "sme_dx_adoption": null,
  "large_company_dx_adoption": null,
  "companies_using_cloud": null,
  "companies_using_ai": null,
  "companies_using_iot": null,
  "companies_using_big_data": null,
  "digital_literacy_rate": null,
  "digital_skills_workforce": null,
  "digital_training_programs": null,
  "people_trained_digital": null,
  "ai_projects": null,
  "iot_projects": null,
  "blockchain_projects": null,
  "smart_city_projects": null,
  "smart_agriculture_area": null,
  "agricultural_iot_adoption": null,
  "agricultural_digital_platforms": null,
  "telemedicine_facilities": null,
  "electronic_health_records_rate": null,
  "health_digital_platforms": null,
  "notes": null
}}

Gi·∫£i th√≠ch c√°c tr∆∞·ªùng:
- location (string): T√™n ƒë·ªãa ph∆∞∆°ng (t·ªânh/th√†nh/huy·ªán/x√£)
- year/quarter/month (int): Th·ªùi gian
- dx_index (float): Ch·ªâ s·ªë chuy·ªÉn ƒë·ªïi s·ªë t·ªïng h·ª£p (0-100)
- dx_readiness_index (float): Ch·ªâ s·ªë s·∫µn s√†ng chuy·ªÉn ƒë·ªïi s·ªë (0-100)
- dx_maturity_level (string): M·ª©c ƒë·ªô tr∆∞·ªüng th√†nh CƒêS (basic/intermediate/advanced/leading)
- dx_ranking (int): X·∫øp h·∫°ng CƒêS to√†n qu·ªëc
- egov_index (float): Ch·ªâ s·ªë ch√≠nh quy·ªÅn ƒëi·ªán t·ª≠ (0-100)
- online_public_services (int): S·ªë d·ªãch v·ª• c√¥ng tr·ª±c tuy·∫øn
- level3_services (int): S·ªë d·ªãch v·ª• c√¥ng m·ª©c ƒë·ªô 3
- level4_services (int): S·ªë d·ªãch v·ª• c√¥ng m·ª©c ƒë·ªô 4
- online_service_usage_rate (float): T·ª∑ l·ªá s·ª≠ d·ª•ng d·ªãch v·ª• c√¥ng tr·ª±c tuy·∫øn (%)
- government_portals (int): S·ªë c·ªïng th√¥ng tin ƒëi·ªán t·ª≠
- integrated_databases (int): S·ªë c∆° s·ªü d·ªØ li·ªáu ƒë∆∞·ª£c t√≠ch h·ª£p
- shared_databases (int): S·ªë CSDL d√πng chung
- data_sharing_rate (float): T·ª∑ l·ªá chia s·∫ª d·ªØ li·ªáu li√™n th√¥ng (%)
- cloud_adoption_rate (float): T·ª∑ l·ªá s·ª≠ d·ª•ng ƒëi·ªán to√°n ƒë√°m m√¢y (%)
- data_centers (int): S·ªë trung t√¢m d·ªØ li·ªáu
- broadband_coverage (float): T·ª∑ l·ªá ph·ªß s√≥ng bƒÉng th√¥ng r·ªông (%)
- fiber_optic_coverage (float): T·ª∑ l·ªá ph·ªß s√≥ng c√°p quang (%)
- fiveg_coverage (float): T·ª∑ l·ªá ph·ªß s√≥ng 5G (%)
- sme_dx_adoption (float): T·ª∑ l·ªá SME th·ª±c hi·ªán CƒêS (%)
- large_company_dx_adoption (float): T·ª∑ l·ªá DN l·ªõn th·ª±c hi·ªán CƒêS (%)
- companies_using_cloud (int): S·ªë DN s·ª≠ d·ª•ng cloud
- companies_using_ai (int): S·ªë DN ·ª©ng d·ª•ng AI
- companies_using_iot (int): S·ªë DN ·ª©ng d·ª•ng IoT
- companies_using_big_data (int): S·ªë DN s·ª≠ d·ª•ng Big Data
- digital_literacy_rate (float): T·ª∑ l·ªá bi·∫øt ch·ªØ s·ªë (%)
- digital_skills_workforce (float): T·ª∑ l·ªá lao ƒë·ªông c√≥ k·ªπ nƒÉng s·ªë (%)
- digital_training_programs (int): S·ªë ch∆∞∆°ng tr√¨nh ƒë√†o t·∫°o k·ªπ nƒÉng s·ªë
- people_trained_digital (int): S·ªë ng∆∞·ªùi ƒë∆∞·ª£c ƒë√†o t·∫°o CƒêS
- ai_projects (int): S·ªë d·ª± √°n AI tri·ªÉn khai
- iot_projects (int): S·ªë d·ª± √°n IoT tri·ªÉn khai
- blockchain_projects (int): S·ªë d·ª± √°n Blockchain
- smart_city_projects (int): S·ªë d·ª± √°n th√†nh ph·ªë th√¥ng minh
- smart_agriculture_area (float): Di·ªán t√≠ch n√¥ng nghi·ªáp th√¥ng minh (ha)
- agricultural_iot_adoption (float): T·ª∑ l·ªá ·ª©ng d·ª•ng IoT n√¥ng nghi·ªáp (%)
- agricultural_digital_platforms (int): S·ªë n·ªÅn t·∫£ng s·ªë n√¥ng nghi·ªáp
- telemedicine_facilities (int): S·ªë c∆° s·ªü y t·∫ø kh√°m ch·ªØa b·ªánh t·ª´ xa
- electronic_health_records_rate (float): T·ª∑ l·ªá b·ªánh √°n ƒëi·ªán t·ª≠ (%)
- health_digital_platforms (int): S·ªë n·ªÅn t·∫£ng s·ªë y t·∫ø
- notes (string): Th√¥ng tin b·ªï sung

QUY T·∫ÆC:
1. LINH HO·∫†T: Extract B·∫§T K·ª≤ ch·ªâ s·ªë CHUY·ªÇN ƒê·ªîI S·ªê n√†o (kh√¥ng c·∫ßn ƒë·∫ßy ƒë·ªß t·∫•t c·∫£ fields)
2. C√°c t·ª´ kh√≥a c·∫ßn ch√∫ √Ω:
   - Chuy·ªÉn ƒë·ªïi s·ªë, CDS, Digital Transformation, DX
   - Ch√≠nh quy·ªÅn ƒëi·ªán t·ª≠, ch√≠nh quy·ªÅn s·ªë, e-government
   - D·ªãch v·ª• c√¥ng tr·ª±c tuy·∫øn, m·ª©c ƒë·ªô 3, m·ª©c ƒë·ªô 4
   - C·ªïng th√¥ng tin ƒëi·ªán t·ª≠, CSDL d√πng chung, chia s·∫ª d·ªØ li·ªáu
   - Cloud, ƒëi·ªán to√°n ƒë√°m m√¢y, trung t√¢m d·ªØ li·ªáu
   - BƒÉng th√¥ng r·ªông, c√°p quang, 4G, 5G
   - Smart city, th√†nh ph·ªë th√¥ng minh
   - AI, IoT, Blockchain, Big Data
   - N√¥ng nghi·ªáp th√¥ng minh, y t·∫ø t·ª´ xa, b·ªánh √°n ƒëi·ªán t·ª≠
   - K·ªπ nƒÉng s·ªë, ƒë√†o t·∫°o s·ªë
3. üìà Ch·ªâ s·ªë v√† x·∫øp h·∫°ng:
   - Ch·ªâ s·ªë CƒêS th∆∞·ªùng l√† s·ªë t·ª´ 0-100
   - X·∫øp h·∫°ng to√†n qu·ªëc (VD: "x·∫øp th·ª© 5/63 t·ªânh")
   - M·ª©c ƒë·ªô tr∆∞·ªüng th√†nh: basic, intermediate, advanced, leading
4. Nh·∫≠n di·ªán ƒë·ªãa ƒëi·ªÉm: Tr√≠ch xu·∫•t t√™n t·ªânh/th√†nh/huy·ªán/x√£ t·ª´ vƒÉn b·∫£n
5. ‚è∞ Th·ªùi gian:
   - "Qu√Ω I/II/III/IV" ‚Üí quarter=1/2/3/4
   - "6 th√°ng ƒë·∫ßu nƒÉm" ‚Üí quarter=2
   - "9 th√°ng" ‚Üí quarter=3
   - "NƒÉm 2024" ‚Üí year=2024
6. CH·ªà tr·∫£ v·ªÅ {{"no_data": true}} n·∫øu vƒÉn b·∫£n HO√ÄN TO√ÄN KH√îNG c√≥ ch·ªâ s·ªë chuy·ªÉn ƒë·ªïi s·ªë

VƒÉn b·∫£n:
\"\"\"
{content[:4000]}
\"\"\"

Ch·ªâ tr·∫£ v·ªÅ JSON."""

    try:
        result = call_llm(prompt)
        if not result:
            return None
        
        json_start = result.find("{")
        json_end = result.rfind("}") + 1
        if json_start == -1:
            return None
        
        data = json.loads(result[json_start:json_end])
        
        if data.get("no_data"):
            return None
        
        # Set province from location or use default
        location = data.pop("location", None)
        if location:
            data["province"] = location
        else:
            data["province"] = province
        
        data["source_post_id"] = post_id
        data["source_url"] = url if url and url.startswith("http") else None
        data["data_source"] = "LLM Extraction"
        data["extraction_metadata"] = json.dumps({"model": LLM_MODEL, "timestamp": datetime.now().isoformat()})
        
        return data
        
    except Exception as e:
        logger.error(f"L·ªói extract digital_transformation: {e}")
        return None


def process_post(post: Dict, db) -> int:
    """X·ª≠ l√Ω 1 post - Extract chuy·ªÉn ƒë·ªïi s·ªë"""
    post_id = post.get("id")
    content = post.get("content", "")
    title = post.get("title", "")
    province = post.get("province", "H∆∞ng Y√™n")
    url = post.get("url") or None
    
    logger.info(f"\n{'='*60}")
    logger.info(f"Post ID: {post_id}")
    logger.info(f"Title: {title[:100]}")
    
    data = extract_digital_transformation_data(content, url, post_id, province)
    if data:
        if save_to_digital_transformation(db, data):
            logger.info(f"Saved to digital_transformation_detail")
            return 1
        else:
            logger.error(f"Failed to save digital_transformation_detail")
    
    return 0


def main():
    """Main function"""
    logger.info("="*80)
    logger.info("B·∫ÆT ƒê·∫¶U LLM EXTRACTION - CHUY·ªÇN ƒê·ªîI S·ªê")
    logger.info(f"Th·ªùi gian: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("="*80)
    
    db = SessionLocal()
    try:
        posts = get_posts_from_db(limit=BATCH_SIZE)
        
        if not posts:
            return {
                "status": "no_data",
                "message": "Kh√¥ng c√≥ posts v·ªÅ chuy·ªÉn ƒë·ªïi s·ªë",
                "processed": 0
            }
        
        total_extracted = 0
        
        for i, post in enumerate(posts, 1):
            logger.info(f"\nProgress: {i}/{len(posts)}")
            try:
                total_extracted += process_post(post, db)
                time.sleep(DELAY_BETWEEN_CALLS)
            except Exception as e:
                logger.error(f"L·ªói: {e}")
        
        logger.info("\n" + "="*80)
        logger.info(f"ƒê√£ x·ª≠ l√Ω: {len(posts)} posts")
        logger.info(f"Extracted: {total_extracted} records")
        logger.info("="*80)
        
        return {
            "status": "success",
            "processed": len(posts),
            "extracted": total_extracted
        }
    finally:
        db.close()


if __name__ == "__main__":
    main()
