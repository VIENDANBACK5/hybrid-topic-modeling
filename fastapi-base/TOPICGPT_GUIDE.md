# TopicGPT Integration Guide

## üé® TopicGPT - LLM-Powered Topic Intelligence

TopicGPT l√† service s·ª≠ d·ª•ng GPT-4 ƒë·ªÉ n√¢ng cao ch·∫•t l∆∞·ª£ng topic modeling.

## üöÄ C·∫•u h√¨nh

```bash
# Required
export OPENAI_API_KEY='sk-...'

# Optional
export TOPICGPT_API='openai'  # ho·∫∑c 'gemini'
export TOPICGPT_MODEL='gpt-4o-mini'  # cost-efficient
```

## üéØ Kh·∫£ nƒÉng TopicGPT

### 1Ô∏è‚É£ **Topic Modeling Enhancements**

#### Generate Topic Labels
```python
from app.services.topic.topicgpt_service import get_topicgpt_service

service = get_topicgpt_service()
label = service.generate_topic_label(
    keywords=["kinh t·∫ø", "th·ªã tr∆∞·ªùng", "ƒë·∫ßu t∆∞"],
    representative_docs=["Th·ªã tr∆∞·ªùng ch·ª©ng kho√°n..."]
)
# Output: "Kinh t·∫ø & Th·ªã tr∆∞·ªùng"
```

#### Generate Descriptions
```python
description = service.generate_topic_description(
    topic_label="Gi√°o d·ª•c & ƒê√†o t·∫°o",
    keywords=["h·ªçc sinh", "tr∆∞·ªùng h·ªçc", "gi√°o vi√™n"],
    representative_docs=[...]
)
```

#### Refine & Merge Similar Topics
```python
result = service.refine_topics(
    topics=[
        {"label": "Kinh t·∫ø ƒë·ªãa ph∆∞∆°ng", "keywords": ["kinh t·∫ø", "doanh nghi·ªáp"]},
        {"label": "Ph√°t tri·ªÉn kinh t·∫ø", "keywords": ["ƒë·∫ßu t∆∞", "kinh t·∫ø"]}
    ],
    merge_threshold=0.85
)
# Suggests: Merge topic 1 & 2 ‚Üí "Ph√°t tri·ªÉn Kinh t·∫ø ƒê·ªãa ph∆∞∆°ng"
```

### 2Ô∏è‚É£ **Content Analysis**

#### Categorize Content
```python
result = service.categorize_content(
    text="H√¥m nay, UBND t·ªânh H∆∞ng Y√™n t·ªï ch·ª©c h·ªçp b√°o...",
    categories=["Ch√≠nh tr·ªã", "Kinh t·∫ø", "X√£ h·ªôi", ...]
)
# Output: {"category": "Ch√≠nh tr·ªã", "confidence": 0.92}
```

#### Extract Keywords & Tags
```python
result = service.extract_keywords_and_tags(
    text="...",
    max_keywords=10
)
# Output: {
#   "keywords": ["h∆∞ng y√™n", "ubnd", "h·ªçp b√°o"],
#   "tags": ["#hungyentoday", "#chinhquyen", "#tintuc"]
# }
```

#### Generate Summaries
```python
summary = service.summarize_content(
    text="Long article...",
    max_length=100
)
```

#### Detect Similarity
```python
similarity = service.detect_similarity(
    text1="Article about economy...",
    text2="Another economic article..."
)
# Output: 0.87 (very similar)
```

## üì° API Endpoints

### Check Status
```bash
curl http://localhost:7777/api/topicgpt/status
```

### Enhance Custom Topics
```bash
# T·∫°o descriptions cho 12 custom topics
curl -X POST http://localhost:7777/api/topicgpt/enhance/custom-topics
```

### Refine Discovered Topics
```bash
# Ph√¢n t√≠ch v√† suggest merge topics t∆∞∆°ng t·ª±
curl -X POST "http://localhost:7777/api/topicgpt/refine/discovered-topics?merge_similar=true"
```

### Categorize Articles
```bash
# Ph√¢n lo·∫°i 100 articles ch∆∞a c√≥ category
curl -X POST "http://localhost:7777/api/topicgpt/categorize-articles?limit=100"
```

### Generate Summaries
```bash
# T·∫°o summary cho 50 articles
curl -X POST "http://localhost:7777/api/topicgpt/generate-summaries?limit=50"
```

### Analyze Content
```bash
curl -X POST http://localhost:7777/api/topicgpt/analyze-content \
  -H "Content-Type: application/json" \
  -d '{
    "text": "H√¥m nay, UBND t·ªânh H∆∞ng Y√™n...",
    "max_keywords": 10
  }'
```

## üîÑ T√≠ch h·ª£p v√†o Pipeline

TopicGPT **ƒë√£ ƒë∆∞·ª£c enable by default** trong:

### 1. BERTopic Training
```bash
# Full pipeline with TopicGPT
curl -X POST http://localhost:7777/api/orchestrator/run-full-pipeline

# Train ri√™ng v·ªõi TopicGPT
curl -X POST http://localhost:7777/api/topics/train \
  -H "Content-Type: application/json" \
  -d '{"enable_topicgpt": true}'
```

**TopicGPT s·∫Ω:**
- Generate natural labels cho discovered topics
- T·∫°o descriptions chi ti·∫øt
- S·ª≠ d·ª•ng representative documents ƒë·ªÉ hi·ªÉu context

### 2. Custom Workflow
```python
from app.services.topic.topicgpt_enhancer import get_enhancer

db = SessionLocal()
enhancer = get_enhancer(db)

# Enhance custom topics
result = enhancer.enhance_custom_topics()

# Refine discovered topics
result = enhancer.refine_discovered_topics(merge_similar=True)

# Categorize articles
result = enhancer.categorize_articles(limit=100)

# Generate summaries
result = enhancer.generate_summaries(limit=50)

db.close()
```

## üí∞ Cost Optimization

TopicGPT c√≥ **caching t·ª± ƒë·ªông**:
- K·∫øt qu·∫£ ƒë∆∞·ª£c cache trong `data/cache/topicgpt/cache.json`
- Gi·∫£m API calls cho queries gi·ªëng nhau
- Ti·∫øt ki·ªám chi ph√≠ ƒë√°ng k·ªÉ

**Model m·∫∑c ƒë·ªãnh:** `gpt-4o-mini` (cost-efficient)
- ~100x r·∫ª h∆°n GPT-4
- Quality v·∫´n cao cho Vietnamese content

## üìä Use Cases

### Use Case 1: Enhance Topics H√†ng tu·∫ßn
```bash
# Sau khi train BERTopic
curl -X POST http://localhost:7777/api/topicgpt/refine/discovered-topics
```

### Use Case 2: Auto-categorize Articles M·ªõi
```bash
# Ch·∫°y h√†ng ng√†y
curl -X POST "http://localhost:7777/api/topicgpt/categorize-articles?limit=100&uncategorized_only=true"
```

### Use Case 3: Generate Summaries cho Dashboard
```bash
# T·∫°o summaries cho trending articles
curl -X POST "http://localhost:7777/api/topicgpt/generate-summaries?limit=30"
```

### Use Case 4: Content Analysis API
```bash
# Real-time analysis cho new content
curl -X POST http://localhost:7777/api/topicgpt/analyze-content \
  -d '{"text": "New article content..."}'
```

## üîß Advanced Features

### Custom Categories
```python
service = get_topicgpt_service()
result = service.categorize_content(
    text="...",
    categories=[
        "N√¥ng nghi·ªáp",
        "C√¥ng nghi·ªáp",
        "D·ªãch v·ª•",
        "Du l·ªãch",
        "ƒê·∫ßu t∆∞"
    ]
)
```

### Merge Topics Automatically
```python
enhancer = get_enhancer(db)
result = enhancer.refine_discovered_topics(
    merge_similar=True,
    merge_threshold=0.9  # Very similar only
)

# Apply merge suggestions manually
for merge in result["merge_suggestions"]:
    print(f"Merge topics {merge['topics']} ‚Üí {merge['new_name']}")
```

## ‚ö†Ô∏è Important Notes

1. **API Key Required**: OPENAI_API_KEY must be set
2. **Rate Limits**: OpenAI has rate limits, use caching
3. **Cost**: Monitor usage with large datasets
4. **Language**: Optimized for Vietnamese content
5. **Quality**: GPT-4o-mini provides excellent results for topic modeling

## üìà Performance

- **Speed**: ~2-3s per API call (cached: instant)
- **Quality**: Natural labels, accurate categorization
- **Cost**: ~$0.001 per 1000 tokens with gpt-4o-mini
- **Cache Hit Rate**: 60-80% for repeated queries

## üéØ Next Steps

1. **Enable**: Set OPENAI_API_KEY
2. **Test**: `curl http://localhost:7777/api/topicgpt/status`
3. **Enhance**: `curl -X POST .../enhance/custom-topics`
4. **Automate**: Add to daily/weekly pipeline

---

**Documentation**: http://localhost:7777/docs (section "üé® TopicGPT")
