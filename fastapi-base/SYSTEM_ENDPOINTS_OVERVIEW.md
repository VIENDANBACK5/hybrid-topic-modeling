# ğŸ¯ Há»† THá»NG ENDPOINTS - OVERVIEW

## ğŸ“Š 2 LUá»’NG CHÃNH

### **LUá»’NG 1: DATA PIPELINE (ETL)**
> Láº¥y data â†’ Xá»­ lÃ½ â†’ LÆ°u file â†’ Load DB

### **LUá»’NG 2: TRAINING & FILL DB**
> Train topics â†’ Classify â†’ Sentiment â†’ Statistics â†’ Fill tables

---

## ğŸ”„ LUá»’NG 1: DATA PIPELINE (ETL)

### Step 1: Láº¥y data tá»« external API
```bash
POST /api/data/fetch-external
```
**Input:** External API URL  
**Output:** `data/raw/raw_20260104_120000.json`

**Example:**
```bash
curl -X POST http://localhost:7777/api/data/fetch-external \
  -H "Content-Type: application/json" \
  -d '{
    "api_url": "http://192.168.30.28:8000/api/articles",
    "params": {"limit": 500}
  }'
```

### Step 2: Xá»­ lÃ½ raw data
```bash
POST /api/data/process
```
**Input:** Raw file path  
**Output:** `data/processed/processed_20260104_120000.json`

**Processing:**
- âœ… Clean HTML tags, special chars
- âœ… Normalize structure
- âœ… Validate content
- âœ… Extract metadata

**Example:**
```bash
curl -X POST http://localhost:7777/api/data/process \
  -H "Content-Type: application/json" \
  -d '{
    "raw_file": "data/raw/raw_20260104_120000.json"
  }'
```

### Step 3: Load vÃ o database
```bash
POST /api/data/load-to-db
```
**Input:** Processed file path  
**Output:** Insert/update articles table

**Example:**
```bash
curl -X POST http://localhost:7777/api/data/load-to-db \
  -H "Content-Type: application/json" \
  -d '{
    "processed_file": "data/processed/processed_20260104_120000.json",
    "update_existing": false
  }'
```

### âš¡ ONE-COMMAND: Full ETL
```bash
POST /api/data/full-etl
```
**Actions:** Fetch â†’ Process â†’ Load (táº¥t cáº£ trong 1 call)

**Example:**
```bash
curl -X POST "http://localhost:7777/api/data/full-etl?external_api_url=http://192.168.30.28:8000/api/articles&limit=500"
```

---

## ğŸ¤– LUá»’NG 2: TRAINING & FILL DATABASE

### Option A: Full Pipeline (ALL-IN-ONE)
```bash
POST /api/orchestrator/run-full-pipeline
```
**Actions:**
1. âœ… Classify topics (12 custom topics)
2. âœ… Analyze sentiment & link to topics
3. âœ… Calculate statistics (trends, hot topics)
4. âœ… Regenerate keywords vá»›i GPT
5. âœ… Train BERTopic (discover new topics)

**Example:**
```bash
curl -X POST http://localhost:7777/api/orchestrator/run-full-pipeline
```

**Result:**
- âœ… `article_custom_topics` - Classified articles
- âœ… `sentiment_analysis` - Sentiment scores
- âœ… `topic_mention_stats` - Topic statistics
- âœ… `keyword_stats` - Top keywords
- âœ… `bertopic_discovered_topics` - Discovered topics
- âœ… `article_bertopic_topics` - Article-topic mappings
- âœ… `trend_reports` - Weekly trends
- âœ… `hot_topics` - Trending topics

### Option B: Quick Update (HÃ ng ngÃ y)
```bash
POST /api/orchestrator/quick-update
```
**Actions:** Chá»‰ classify + sentiment + keywords (skip training)

**Example:**
```bash
curl -X POST "http://localhost:7777/api/orchestrator/quick-update?limit=100"
```

### Option C: RiÃªng tá»«ng pháº§n

#### Train BERTopic only
```bash
POST /api/topics/train
```
**Input:** Processed file hoáº·c database  
**Output:** Discovered topics

**Example:**
```bash
# Train tá»« processed file
curl -X POST http://localhost:7777/api/topics/train \
  -H "Content-Type: application/json" \
  -d '{
    "from_processed_file": "data/processed/processed_20260104_120000.json",
    "min_topic_size": 10,
    "enable_topicgpt": true
  }'

# Train tá»« database
curl -X POST http://localhost:7777/api/topics/train \
  -d '{"limit": 500}'
```

#### Enhance vá»›i TopicGPT
```bash
POST /api/topicgpt/enhance/custom-topics
POST /api/topicgpt/refine/discovered-topics
POST /api/topicgpt/categorize-articles
POST /api/topicgpt/generate-summaries
```

**Example:**
```bash
# Enhance 12 custom topics
curl -X POST http://localhost:7777/api/topicgpt/enhance/custom-topics

# Categorize articles
curl -X POST "http://localhost:7777/api/topicgpt/categorize-articles?limit=100"
```

---

## ğŸ¯ WORKFLOWS THá»°C Táº¾

### Workflow 1: Data má»›i tá»« external API â†’ Train toÃ n bá»™

```bash
# Step 1: Full ETL (fetch + process + load)
curl -X POST "http://localhost:7777/api/data/full-etl?external_api_url=http://192.168.30.28:8000/api/articles"

# Step 2: Full pipeline (classify + train + stats)
curl -X POST http://localhost:7777/api/orchestrator/run-full-pipeline
```

**Káº¿t quáº£:** Táº¥t cáº£ tables filled, topics discovered!

### Workflow 2: Train tá»« processed file (khÃ´ng dÃ¹ng DB)

```bash
# Step 1: Fetch + process (khÃ´ng load DB)
curl -X POST http://localhost:7777/api/data/fetch-external \
  -d '{"api_url": "http://api.com/data"}'
# â†’ data/raw/raw_xxx.json

curl -X POST http://localhost:7777/api/data/process \
  -d '{"raw_file": "data/raw/raw_xxx.json"}'
# â†’ data/processed/processed_xxx.json

# Step 2: Train trá»±c tiáº¿p tá»« file
curl -X POST http://localhost:7777/api/topics/train \
  -d '{"from_processed_file": "data/processed/processed_xxx.json"}'
```

**Káº¿t quáº£:** Topics discovered, saved to `bertopic_discovered_topics`

### Workflow 3: Update hÃ ng ngÃ y (incremental)

```bash
# Fetch data má»›i (100 records)
curl -X POST "http://localhost:7777/api/data/full-etl?use_database=false&external_api_url=http://api.com/data&limit=100"

# Quick update (khÃ´ng train láº¡i)
curl -X POST "http://localhost:7777/api/orchestrator/quick-update?limit=100"
```

**Káº¿t quáº£:** Articles classified, sentiment analyzed, keywords updated

### Workflow 4: Re-train toÃ n bá»™ tá»« DB

```bash
# Export DB â†’ processed file
curl -X POST "http://localhost:7777/api/data/export-db-to-raw?limit=1000"

# Process
curl -X POST http://localhost:7777/api/data/process \
  -d '{"raw_file": "data/raw/raw_from_db_xxx.json"}'

# Train
curl -X POST http://localhost:7777/api/topics/train \
  -d '{"from_processed_file": "data/processed/processed_xxx.json"}'
```

---

## ğŸ“Š TABLES ÄÆ¯á»¢C FILL

### Sau LUá»’NG 1 (ETL):
| Table | Description |
|-------|-------------|
| `articles` | Raw articles data |

### Sau LUá»’NG 2 (Training & Fill):
| Table | Description | Filled by |
|-------|-------------|-----------|
| `article_custom_topics` | Article classifications | Classifier |
| `sentiment_analysis` | Sentiment scores | Sentiment service |
| `topic_mention_stats` | Topic statistics per period | Statistics service |
| `keyword_stats` | Top keywords vá»›i GPT | Statistics service |
| `bertopic_discovered_topics` | Discovered topics | BERTopic |
| `article_bertopic_topics` | Article-topic mappings | BERTopic |
| `topic_training_sessions` | Training history | BERTopic trainer |
| `trend_reports` | Weekly trends | Statistics service |
| `hot_topics` | Top trending topics | Statistics service |
| `daily_snapshots` | Daily metrics | Statistics service |

---

## ğŸ¯ DECISION TREE

```
Báº N Cáº¦N GÃŒ?

â”Œâ”€ Láº¥y data má»›i tá»« API khÃ¡c?
â”‚  â””â”€ POST /api/data/fetch-external
â”‚     â””â”€ POST /api/data/process
â”‚        â””â”€ POST /api/data/load-to-db
â”‚
â”Œâ”€ Fill táº¥t cáº£ tables vá»›i data cÃ³ sáºµn?
â”‚  â””â”€ POST /api/orchestrator/run-full-pipeline
â”‚
â”Œâ”€ Chá»‰ train topics (khÃ´ng cáº§n classify)?
â”‚  â””â”€ POST /api/topics/train
â”‚
â”Œâ”€ Update nhanh data má»›i?
â”‚  â””â”€ POST /api/orchestrator/quick-update
â”‚
â”Œâ”€ Enhance topics vá»›i GPT?
â”‚  â””â”€ POST /api/topicgpt/enhance/custom-topics
â”‚
â””â”€ ALL-IN-ONE tá»« Ä‘áº§u Ä‘áº¿n cuá»‘i?
   â””â”€ POST /api/data/full-etl (fetch + process + load)
      â””â”€ POST /api/orchestrator/run-full-pipeline (train + fill)
```

---

## ğŸ” CHECK STATUS

```bash
# System status
curl http://localhost:7777/api/orchestrator/status

# Files available
curl http://localhost:7777/api/data/files/processed

# Topics discovered
curl http://localhost:7777/api/topics/discovered?limit=20

# Training sessions
curl http://localhost:7777/api/topics/sessions
```

---

## ğŸ“š API DOCUMENTATION

**Swagger UI:** http://localhost:7777/docs

**Sections:**
- ğŸ“Š Data Pipeline - ETL endpoints
- ğŸ¯ Orchestrator - Full pipeline
- ğŸ§  Topic Training - BERTopic
- ğŸ¨ TopicGPT - LLM enhancements
- ğŸ“ˆ Statistics - Keywords & stats

---

## âœ… TÃ“M Táº®T

### LUá»’NG 1: ETL
```
External API â†’ data/raw/ â†’ data/processed/ â†’ Database (articles)
```

### LUá»’NG 2: FILL DB
```
articles â†’ classify â†’ sentiment â†’ keywords â†’ train â†’ ALL TABLES FILLED
```

### ONE-COMMAND
```bash
# Fetch + Process + Load + Train + Fill everything
curl -X POST "http://localhost:7777/api/data/full-etl?external_api_url=..."
curl -X POST "http://localhost:7777/api/orchestrator/run-full-pipeline"
```

**2 dÃ²ng lá»‡nh = Full system ready! ğŸ‰**
