#!/usr/bin/env python3
"""
Script Ä‘á»ƒ fetch newspaper data tá»« external API
Sá»­ dá»¥ng endpoint má»›i vá»›i tÃ­nh nÄƒng phÃ¢n trang vÃ  deduplication
"""
import requests
import json
import sys
from typing import Optional

# API Configuration
API_BASE_URL = "http://localhost:7777"
EXTERNAL_API_URL = "http://192.168.30.28:8548/api/v1/posts/by-type/newspaper"


def fetch_newspaper_raw_all(
    page_size: int = 100,
    max_pages: Optional[int] = None
) -> dict:
    """
    Fetch Táº¤T Cáº¢ data (ká»ƒ cáº£ duplicate) - khÃ´ng filter gÃ¬ cáº£
    """
    url = f"{API_BASE_URL}/api/data/fetch-newspaper-raw-all"
    
    payload = {
        "base_api_url": EXTERNAL_API_URL,
        "page_size": page_size,
        "max_pages": max_pages,
        "sort_by": "id",
        "order": "desc"
    }
    
    print("Fetching ALL newspaper data (no deduplication)...")
    print(f"   API: {EXTERNAL_API_URL}")
    print(f"   Page size: {page_size}")
    print(f"   Max pages: {max_pages or 'unlimited'}")
    print()
    
    response = requests.post(url, json=payload)
    response.raise_for_status()
    
    return response.json()


def fetch_newspaper_only(
    page_size: int = 100,
    max_pages: Optional[int] = None
) -> dict:
    """
    Fetch vÃ  filter duplicate vá»›i DB, chá»‰ lÆ°u data má»›i
    """
    url = f"{API_BASE_URL}/api/data/fetch-newspaper"
    
    payload = {
        "base_api_url": EXTERNAL_API_URL,
        "page_size": page_size,
        "max_pages": max_pages,
        "sort_by": "id",
        "order": "desc"
    }
    
    print("Fetching newspaper data...")
    print(f"   API: {EXTERNAL_API_URL}")
    print(f"   Page size: {page_size}")
    print(f"   Max pages: {max_pages or 'unlimited'}")
    print()
    
    response = requests.post(url, json=payload)
    response.raise_for_status()
    
    return response.json()


def fetch_newspaper_full_etl(
    page_size: int = 100,
    max_pages: Optional[int] = None,
    update_existing: bool = False
) -> dict:
    """
    Fetch vÃ  cháº¡y FULL ETL: Fetch â†’ Process â†’ Load to DB
    """
    url = f"{API_BASE_URL}/api/data/fetch-newspaper-full-etl"
    
    params = {"update_existing": update_existing}
    
    payload = {
        "base_api_url": EXTERNAL_API_URL,
        "page_size": page_size,
        "max_pages": max_pages,
        "sort_by": "id",
        "order": "desc"
    }
    
    print("ðŸ”„ Running FULL ETL for newspaper data...")
    print(f"   API: {EXTERNAL_API_URL}")
    print(f"   Page size: {page_size}")
    print(f"   Max pages: {max_pages or 'unlimited'}")
    print(f"   Update existing: {update_existing}")
    print()
    
    response = requests.post(url, json=payload, params=params)
    response.raise_for_status()
    
    return response.json()


def print_results(result: dict):
    """In káº¿t quáº£"""
    print("\n" + "="*60)
    print(f"Status: {result['status']}")
    print(f"Message: {result.get('message', 'N/A')}")
    
    if 'statistics' in result:
        print("\nStatistics:")
        stats = result['statistics']
        for key, value in stats.items():
            print(f"   {key}: {value}")
    
    if 'results' in result and 'steps' in result['results']:
        print("\nðŸ“‹ Pipeline Steps:")
        for step in result['results']['steps']:
            print(f"   {step['name']}: {step['status']}")
            if 'statistics' in step:
                for key, value in step['statistics'].items():
                    print(f"      {key}: {value}")
    
    if 'raw_file' in result:
        print(f"\nðŸ’¾ Raw file: {result['raw_file']}")
    
    print("="*60)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Fetch newspaper data from external API")
    parser.add_argument(
        "--mode",
        choices=["fetch-all", "fetch-only", "full-etl"],
        default="full-etl",
        help="Mode: fetch-all (láº¥y háº¿t, khÃ´ng filter), fetch-only (chá»‰ fetch data má»›i), full-etl (fetch + process + load)"
    )
    parser.add_argument(
        "--page-size",
        type=int,
        default=100,
        help="Sá»‘ records má»—i trang (default: 100)"
    )
    parser.add_argument(
        "--max-pages",
        type=int,
        default=None,
        help="Giá»›i háº¡n sá»‘ trang (default: None = unlimited)"
    )
    parser.add_argument(
        "--update-existing",
        action="store_true",
        help="Update existing records (chá»‰ cho full-etl mode)"
    )
    
    args = parser.parse_args()
    
    try:
        if args.mode == "fetch-all":
            result = fetch_newspaper_raw_all(
                page_size=args.page_size,
                max_pages=args.max_pages
            )
        elif args.mode == "fetch-only":
            result = fetch_newspaper_only(
                page_size=args.page_size,
                max_pages=args.max_pages
            )
        else:  # full-etl
            result = fetch_newspaper_full_etl(
                page_size=args.page_size,
                max_pages=args.max_pages,
                update_existing=args.update_existing
            )
        
        print_results(result)
        
        if result['status'] == 'success':
            sys.exit(0)
        else:
            sys.exit(1)
            
    except requests.exceptions.RequestException as e:
        print(f"\nError: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"\nUnexpected error: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
